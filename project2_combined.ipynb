{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ebaea00146a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "def goodRating(row):\n",
    "    return row >= 3\n",
    "\n",
    "def avgSentiment(row, w_dict):\n",
    "    s = 0\n",
    "    tokens = row.split()\n",
    "    for t in tokens:\n",
    "         s += w_dict[t]\n",
    "    return s/len(tokens)\n",
    "\n",
    "def avgSentiment(row, w_dict):\n",
    "    s = 0\n",
    "    count = 0\n",
    "    tokens = row.split()\n",
    "    for t in tokens:\n",
    "        try:\n",
    "            s += w_dict[t]\n",
    "            count += 1\n",
    "        except:\n",
    "            continue\n",
    "    return s/count\n",
    "\n",
    "def posWords(row, w_dict):\n",
    "    numWords = 0\n",
    "    tokens = row.split()\n",
    "    for t in tokens:\n",
    "        try: \n",
    "            if w_dict[t] > 0:\n",
    "                numWords += 1\n",
    "        except:\n",
    "            continue\n",
    "    return numWords\n",
    "\n",
    "def negWords(row, w_dict):\n",
    "    numWords = 0\n",
    "    tokens = row.split()\n",
    "    for t in tokens:\n",
    "        try: \n",
    "            if w_dict[t] < 0:\n",
    "                numWords += 1\n",
    "        except:\n",
    "            continue\n",
    "    return numWords\n",
    "\n",
    "def date_to_nth_day(date, format='%Y-%m-%d'):\n",
    "    date = pd.to_datetime(date, format=format)\n",
    "    new_year_day = pd.Timestamp(year=date.year, month=1, day=1)\n",
    "    return (date - new_year_day).days + 1\n",
    "\n",
    "# Porter stemmer for text stemming\n",
    "porter = PorterStemmer()\n",
    "\n",
    "stop = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \n",
    "        \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \n",
    "        \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \n",
    "        \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \n",
    "        \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \n",
    "        \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \n",
    "        \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \n",
    "        \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \n",
    "        \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \n",
    "        \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \n",
    "        \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \n",
    "        \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \n",
    "        \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "def avg_word(sentence):\n",
    "    words = sentence.split()\n",
    "    return (sum(len(word) for word in words)/len(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data400_share/beer.csv\")\n",
    "data.drop('index',axis =1, inplace = True)\n",
    "newCols = [col.split('/')[1] for col in data.columns]\n",
    "data = pd.DataFrame(data.values, columns = newCols).drop(['beerId','brewerId'], axis = 1)\n",
    "train=data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sumReviews'] = train['appearance'] + train['aroma'] + train['overall'] + train['palate'] + train['taste']\n",
    "sumMean = train['sumReviews'].mean()\n",
    "train['sumReviews'] =  train['sumReviews'].astype(float)\n",
    "userSumMean = train.groupby(['profileName'])['sumReviews'].mean().reset_index()\n",
    "userSumMean['userBias'] = userSumMean['sumReviews'] - sumMean\n",
    "train = train.merge(userSumMean, left_on='profileName', right_on='profileName', how='left')\n",
    "train = train.drop(['sumReviews_y','sumReviews_x'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Additional featureW\n",
    "train['word_count'] = train['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "train['char_count'] = train['text'].str.len() ## this also includes spaces\n",
    "train['avg_word_len'] = train['text'].apply(lambda x: avg_word(str(x)))\n",
    "train['stopwords'] = train['text'].apply(lambda x: len([x for x in str(x).split() if x in stop]))\n",
    "train['questions'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '?' in str(x)]))\n",
    "train['ellipses'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '...' in str(x)]))\n",
    "train['exclamations'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '!' in str(x)]))\n",
    "train['plus'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '+' in str(x)]))\n",
    "train['star'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '*' in str(x)]))\n",
    "train['numerics'] = train['text'].apply(lambda x: len([x for x in str(x).split() if x.isdigit()]))\n",
    "train['upper'] = train['text'].str.findall(r'[A-Z]').str.len()\n",
    "train['age_years'] = (train['ageInSeconds']/31536000.0)#.apply(np.floor)\n",
    "train['age_years'] = train['age_years'].fillna(0)\n",
    "train['age_years'] = train['age_years'].apply(lambda x: math.floor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-92eb2055d5e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeStruct\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeStruct\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbeerTimeDic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeStruct\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m holidays =[\n\u001b[1;32m      5\u001b[0m   \u001b[0;34m'2012-01-02'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train[\"timeStruct\"] = train[\"timeStruct\"].apply(lambda x: dict(eval(x)))\n",
    "beerTimeDic = train[\"timeStruct\"]\n",
    "\n",
    "holidays =[\n",
    "  '2012-01-02',\n",
    "  '2012-01-16',\n",
    "  '2012-02-20',\n",
    "  '2012-05-28',\n",
    "  '2012-07-04',\n",
    "  '2012-09-03',\n",
    "  '2012-10-08',\n",
    "  '2012-11-12',\n",
    "  '2012-11-22',\n",
    "  '2012-12-25']\n",
    "\n",
    "ydayHoliday = []\n",
    "for date in holidays:\n",
    "    ydayHoliday.append(date_to_nth_day(date))\n",
    "    \n",
    "weekHoliday = []\n",
    "for day in ydayHoliday:\n",
    "    temp = list(range(day-3,day+3))\n",
    "    temp = [x for x in temp if(x>0 & x<367)]\n",
    "    for x in temp:\n",
    "        weekHoliday.append(x)\n",
    "        \n",
    "train[\"isHolidayWeek\"] = train[\"timeStruct\"].apply(lambda x: 1 if x['yday'] in weekHoliday else 0)\n",
    "train[\"isWeekend\"] = train[\"timeStruct\"].apply(lambda x: 1 if x['wday'] in [4,5,6] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-89361df6ccca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert reviews to lower case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Remove punctuation characters from  text review\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[^\\w\\s]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert reviews to lower case\n",
    "train['text'] = train['text'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "\n",
    "# Remove punctuation characters from  text review\n",
    "train['text'] = train['text'].str.replace('[^\\w\\s]','')\n",
    "# Remove stop words\n",
    "train['text'] = train['text'].apply(lambda x: \" \".join(x for x in str(x).split() if x not in stop))\n",
    "\n",
    "# Stem words\n",
    "train['text'] = train['text'].apply((lambda x: \" \".join(porter.stem(x) for x in str(x).split())))\n",
    "\n",
    "# Remove least frequent words\n",
    "l_freq = pd.Series(' '.join(train['text']).split()).value_counts()[-10:]\n",
    "l_freq = list(l_freq.index)\n",
    "train['text'] = train['text'].apply(lambda x: \" \".join(x for x in str(x).split() if x not in l_freq))\n",
    "\n",
    "# Label beer ratings as positive or negative\n",
    "train['target'] = train['overall'].apply(goodRating)\n",
    "train.sort_values(by = 'overall', ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-14fefb3f984d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "text_train = train['text'].values\n",
    "target = train['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0ee40d634032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Vectorize words from beer rating text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#X_test = cv.transform(reviews_test_clean)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_train' is not defined"
     ]
    }
   ],
   "source": [
    "#Vectorize words from beer rating text\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(text_train)\n",
    "X = cv.transform(text_train)\n",
    "#X_test = cv.transform(reviews_test_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-98d92925dbfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train, X_val, y_train, y_val = train_test_split(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mc_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "c_values = np.linspace(.01,1,100)\n",
    "accuracy = []\n",
    "for c in c_values:\n",
    "    lr = LogisticRegression(C=c, solver='liblinear')\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "          # % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    accuracy.append(accuracy_score(y_val, lr.predict(X_val)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C Value: 0.31\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimize the C hyperparameter for regularization \n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.scatter(c_values, accuracy, s = 1.2)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('C')\n",
    "best_c = c_values[accuracy.index(max(accuracy))]\n",
    "print('Best C Value:', best_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.31, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = LogisticRegression(C = best_c, solver = 'liblinear')\n",
    "final_model.fit(X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('easi', 1.4465176248189751)\n",
      "('awesom', 1.1431865461000603)\n",
      "('pleasantli', 1.0064715092298711)\n",
      "('rye', 0.95532128746171441)\n",
      "('tasti', 0.89402913473591283)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print (best_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('drainpour', -1.6224896601715648)\n",
      "('drain', -1.541072678415619)\n",
      "('undrink', -1.2266331631721927)\n",
      "('chemic', -1.2256735898824953)\n",
      "('soap', -1.2054083377454448)\n"
     ]
    }
   ],
   "source": [
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'age'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'age'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-e1dae4807e75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnum_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mminimum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mmaximum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m.00000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'age'"
     ]
    }
   ],
   "source": [
    "train['avg_sent'] = train['text'].apply(avgSentiment, args = (feature_to_coef,))\n",
    "train['#pos_words'] = train['text'].apply(posWords, args = (feature_to_coef,))\n",
    "train['#neg_words'] = train['text'].apply(negWords, args = (feature_to_coef,))\n",
    "train['#pos/#neg'] = train['#pos_words']/train['#neg_words']\n",
    "# Some values turn to infinite due to 0 divison, its fixed below\n",
    "mask = train['#pos/#neg'] != np.inf\n",
    "# Make values that infinite equal to the # pos words\n",
    "train.loc[~mask, '#pos/#neg' ] = train.loc[~mask, '#pos_words']\n",
    "\n",
    "# Gender encoding\n",
    "train['gender'] = train['gender'].fillna('Gender N/A')\n",
    "train = train.join(pd.get_dummies(train['gender']))\n",
    "train.drop(['gender','Female'], axis =1, inplace = True)\n",
    "\n",
    "# Style encoding \n",
    "train = train.join(pd.get_dummies(train['style']))\n",
    "train.drop('style', axis = 1, inplace = True)\n",
    "# Convert all columns that have been transformed and will no longer be used\n",
    "# Drop beer name, cannot one hot encode due to huge dimensionality increase\n",
    "# Drop profile name\n",
    "train.drop(['timeStruct','timeUnix','birthdayRaw','birthdayUnix','ageInSeconds',\n",
    "           'profileName'],\n",
    "           axis = 1, inplace = True)\n",
    "\n",
    "num_cols = ['ABV',\n",
    " 'appearance',\n",
    " 'aroma',\n",
    " 'overall',\n",
    " 'palate',\n",
    " 'taste',\n",
    " 'userBias',\n",
    " 'word_count',\n",
    " 'char_count',\n",
    " 'avg_word_len',\n",
    " 'stopwords',\n",
    " 'questions',\n",
    " 'ellipses',\n",
    " 'exclamations',\n",
    " 'plus',\n",
    " 'star',\n",
    " 'numerics',\n",
    " 'upper',\n",
    " 'age_years',\n",
    " 'avg_sent',\n",
    " '#pos_words',\n",
    " '#neg_words',\n",
    " '#pos/#neg']\n",
    "\n",
    "for col in num_cols:    \n",
    "    minimum = train[col].min()\n",
    "    maximum = train[col].max()\n",
    "    train[col] = (train[col]-(minimum-.00000001)) / (maximum-minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:18: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n"
     ]
    }
   ],
   "source": [
    "open_beer = pd.read_csv('open-beer-database.csv', sep = ';').rename(columns = {'Name':'name'})\n",
    "open_beer = open_beer[['name','Country']]\n",
    "open_beer.drop_duplicates(inplace = True)\n",
    "one_hot = pd.get_dummies(open_beer['Country'],dummy_na = True)\n",
    "open_beer.drop('Country', axis = 1, inplace = True)\n",
    "open_beer = open_beer.join(one_hot)\n",
    "beer_names = list(set(open_beer['name'].values))\n",
    "\n",
    "# Compress one hot encoding to get one beer and all locations into one row\n",
    "beer_locs = []\n",
    "for beer in beer_names:\n",
    "    cur_beer = open_beer[open_beer['name'] == beer]\n",
    "    t = np.zeros(one_hot.shape[1])\n",
    "    for row in cur_beer.iterrows():\n",
    "        index, data = row\n",
    "        t = np.add( t, np.array(data)[1:])\n",
    "    beer_locs.append(t)   \n",
    "final_hot = pd.DataFrame.from_items(zip(one_hot.columns, np.array(beer_locs).T))\n",
    "final_hot['name'] = beer_names\n",
    "\n",
    "merged = pd.merge(train, final_hot, on = 'name', how = 'left')\n",
    "merged.drop(['name','text','target'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('train.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABV',\n",
       " 'appearance',\n",
       " 'aroma',\n",
       " 'overall',\n",
       " 'palate',\n",
       " 'taste',\n",
       " 'userBias',\n",
       " 'word_count',\n",
       " 'char_count',\n",
       " 'avg_word_len',\n",
       " 'stopwords',\n",
       " 'questions',\n",
       " 'ellipses',\n",
       " 'exclamations',\n",
       " 'plus',\n",
       " 'star',\n",
       " 'numerics',\n",
       " 'upper',\n",
       " 'age_years',\n",
       " 'isHolidayWeek',\n",
       " 'isWeekend',\n",
       " 'avg_sent',\n",
       " '#pos_words',\n",
       " '#neg_words',\n",
       " '#pos/#neg',\n",
       " 'Gender N/A',\n",
       " 'Male',\n",
       " 'Altbier',\n",
       " 'American Adjunct Lager',\n",
       " 'American Amber / Red Ale',\n",
       " 'American Amber / Red Lager',\n",
       " 'American Barleywine',\n",
       " 'American Black Ale',\n",
       " 'American Blonde Ale',\n",
       " 'American Brown Ale',\n",
       " 'American Dark Wheat Ale',\n",
       " 'American Double / Imperial IPA',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'American Double / Imperial Stout',\n",
       " 'American IPA',\n",
       " 'American Malt Liquor',\n",
       " 'American Pale Ale (APA)',\n",
       " 'American Pale Lager',\n",
       " 'American Pale Wheat Ale',\n",
       " 'American Porter',\n",
       " 'American Stout',\n",
       " 'American Strong Ale',\n",
       " 'American Wild Ale',\n",
       " 'Baltic Porter',\n",
       " 'Belgian Dark Ale',\n",
       " 'Belgian IPA',\n",
       " 'Belgian Pale Ale',\n",
       " 'Belgian Strong Dark Ale',\n",
       " 'Belgian Strong Pale Ale',\n",
       " 'Berliner Weissbier',\n",
       " 'BiÃ¨re de Garde',\n",
       " 'Black & Tan',\n",
       " 'Bock',\n",
       " 'Braggot',\n",
       " 'California Common / Steam Beer',\n",
       " 'Chile Beer',\n",
       " 'Cream Ale',\n",
       " 'Czech Pilsener',\n",
       " 'Doppelbock',\n",
       " 'Dortmunder / Export Lager',\n",
       " 'Dubbel',\n",
       " 'Dunkelweizen',\n",
       " 'Eisbock',\n",
       " 'English Barleywine',\n",
       " 'English Bitter',\n",
       " 'English Brown Ale',\n",
       " 'English Dark Mild Ale',\n",
       " 'English India Pale Ale (IPA)',\n",
       " 'English Pale Ale',\n",
       " 'English Pale Mild Ale',\n",
       " 'English Porter',\n",
       " 'English Stout',\n",
       " 'English Strong Ale',\n",
       " 'Euro Dark Lager',\n",
       " 'Euro Pale Lager',\n",
       " 'Euro Strong Lager',\n",
       " 'Extra Special / Strong Bitter (ESB)',\n",
       " 'Flanders Oud Bruin',\n",
       " 'Flanders Red Ale',\n",
       " 'Foreign / Export Stout',\n",
       " 'Fruit / Vegetable Beer',\n",
       " 'German Pilsener',\n",
       " 'Hefeweizen',\n",
       " 'Herbed / Spiced Beer',\n",
       " 'Irish Dry Stout',\n",
       " 'Irish Red Ale',\n",
       " 'Keller Bier / Zwickel Bier',\n",
       " 'Kristalweizen',\n",
       " 'KÃ¶lsch',\n",
       " 'Lambic - Fruit',\n",
       " 'Lambic - Unblended',\n",
       " 'Light Lager',\n",
       " 'Low Alcohol Beer',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Milk / Sweet Stout',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Munich Helles Lager',\n",
       " 'MÃ¤rzen / Oktoberfest',\n",
       " 'Oatmeal Stout',\n",
       " 'Old Ale',\n",
       " 'Pumpkin Ale',\n",
       " 'Quadrupel (Quad)',\n",
       " 'Rauchbier',\n",
       " 'Russian Imperial Stout',\n",
       " 'Rye Beer',\n",
       " 'Saison / Farmhouse Ale',\n",
       " 'Schwarzbier',\n",
       " 'Scotch Ale / Wee Heavy',\n",
       " 'Scottish Ale',\n",
       " 'Scottish Gruit / Ancient Herbed Ale',\n",
       " 'Smoked Beer',\n",
       " 'Tripel',\n",
       " 'Vienna Lager',\n",
       " 'Weizenbock',\n",
       " 'Wheatwine',\n",
       " 'Winter Warmer',\n",
       " 'Witbier',\n",
       " 'Argentina',\n",
       " 'Aruba',\n",
       " 'Australia',\n",
       " 'Austria',\n",
       " 'Belgium',\n",
       " 'Belize',\n",
       " 'Brazil',\n",
       " 'Canada',\n",
       " 'China',\n",
       " 'Colombia',\n",
       " 'Croatia',\n",
       " 'Cuba',\n",
       " 'Czech Republic',\n",
       " 'Denmark',\n",
       " 'Egypt',\n",
       " 'El Salvador',\n",
       " 'England',\n",
       " 'Estonia',\n",
       " 'Finland',\n",
       " 'France',\n",
       " 'French Polynesia',\n",
       " 'Germany',\n",
       " 'Greece',\n",
       " 'Guatemala',\n",
       " 'Honduras',\n",
       " 'Hungary',\n",
       " 'India',\n",
       " 'Ireland',\n",
       " 'Israel',\n",
       " 'Italy',\n",
       " 'Jamaica',\n",
       " 'Japan',\n",
       " 'Kenya',\n",
       " 'Korea, Republic of',\n",
       " 'Latvia',\n",
       " 'Lithuania',\n",
       " 'Macao',\n",
       " 'Macedonia, the Former Yugoslav Republic of',\n",
       " 'Mauritius',\n",
       " 'Mexico',\n",
       " 'Myanmar',\n",
       " 'Namibia',\n",
       " 'Netherlands',\n",
       " 'New Zealand',\n",
       " 'Norway',\n",
       " 'Panama',\n",
       " 'Philippines',\n",
       " 'Poland',\n",
       " 'Portugal',\n",
       " 'Russia',\n",
       " 'Sierra Leone',\n",
       " 'Slovakia',\n",
       " 'Spain',\n",
       " 'Sri Lanka',\n",
       " 'Sweden',\n",
       " 'Switzerland',\n",
       " 'Taiwan, Province of China',\n",
       " 'Thailand',\n",
       " 'Togo',\n",
       " 'United Kingdom',\n",
       " 'United States',\n",
       " nan]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(merged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['age']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
