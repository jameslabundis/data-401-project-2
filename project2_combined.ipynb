{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "def goodRating(row):\n",
    "    return row >= 3\n",
    "\n",
    "def avgSentiment(row, w_dict):\n",
    "    s = 0\n",
    "    tokens = row.split()\n",
    "    for t in tokens:\n",
    "         s += w_dict[t]\n",
    "    return s/len(tokens)\n",
    "\n",
    "def avgSentiment(row, w_dict):\n",
    "    s = 0\n",
    "    count = 0\n",
    "    tokens = row.split()\n",
    "    for t in tokens:\n",
    "        try:\n",
    "            s += w_dict[t]\n",
    "            count += 1\n",
    "        except:\n",
    "            continue\n",
    "    return s/count\n",
    "\n",
    "def posWords(row, w_dict):\n",
    "    numWords = 0\n",
    "    tokens = row.split()\n",
    "    for t in tokens:\n",
    "        try: \n",
    "            if w_dict[t] > 0:\n",
    "                numWords += 1\n",
    "        except:\n",
    "            continue\n",
    "    return numWords\n",
    "\n",
    "def negWords(row, w_dict):\n",
    "    numWords = 0\n",
    "    tokens = row.split()\n",
    "    for t in tokens:\n",
    "        try: \n",
    "            if w_dict[t] < 0:\n",
    "                numWords += 1\n",
    "        except:\n",
    "            continue\n",
    "    return numWords\n",
    "\n",
    "def date_to_nth_day(date, format='%Y-%m-%d'):\n",
    "    date = pd.to_datetime(date, format=format)\n",
    "    new_year_day = pd.Timestamp(year=date.year, month=1, day=1)\n",
    "    return (date - new_year_day).days + 1\n",
    "\n",
    "# Porter stemmer for text stemming\n",
    "porter = PorterStemmer()\n",
    "\n",
    "stop = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \n",
    "        \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \n",
    "        \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \n",
    "        \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \n",
    "        \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \n",
    "        \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \n",
    "        \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \n",
    "        \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \n",
    "        \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \n",
    "        \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \n",
    "        \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \n",
    "        \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \n",
    "        \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "def avg_word(sentence):\n",
    "    words = sentence.split()\n",
    "    return (sum(len(word) for word in words)/len(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABV</th>\n",
       "      <th>name</th>\n",
       "      <th>style</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>overall</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>text</th>\n",
       "      <th>timeStruct</th>\n",
       "      <th>timeUnix</th>\n",
       "      <th>ageInSeconds</th>\n",
       "      <th>birthdayRaw</th>\n",
       "      <th>birthdayUnix</th>\n",
       "      <th>gender</th>\n",
       "      <th>profileName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Chiostro</td>\n",
       "      <td>Herbed / Spiced Beer</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Pours a clouded gold with a thin white head. N...</td>\n",
       "      <td>{'min': 38, 'hour': 3, 'mday': 16, 'sec': 10, ...</td>\n",
       "      <td>1229398690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RblWthACoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>Bearded Pat's Barleywine</td>\n",
       "      <td>American Barleywine</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>12oz bottle into 8oz snifter.\\t\\tDeep ruby red...</td>\n",
       "      <td>{'min': 38, 'hour': 23, 'mday': 8, 'sec': 58, ...</td>\n",
       "      <td>1218238738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BeerSox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>Naughty Nellie's Ale</td>\n",
       "      <td>American Pale Ale (APA)</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>First enjoyed at the brewpub about 2 years ago...</td>\n",
       "      <td>{'min': 7, 'hour': 18, 'mday': 26, 'sec': 2, '...</td>\n",
       "      <td>1101492422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>mschofield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4</td>\n",
       "      <td>Pilsner Urquell</td>\n",
       "      <td>Czech Pilsener</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>First thing I noticed after pouring from green...</td>\n",
       "      <td>{'min': 7, 'hour': 1, 'mday': 20, 'sec': 5, 'y...</td>\n",
       "      <td>1308532025</td>\n",
       "      <td>1.20983e+09</td>\n",
       "      <td>Aug 10, 1976</td>\n",
       "      <td>2.08508e+08</td>\n",
       "      <td>Male</td>\n",
       "      <td>molegar76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.4</td>\n",
       "      <td>Black Sheep Ale (Special)</td>\n",
       "      <td>English Pale Ale</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>A: pours an amber with a one finger head but o...</td>\n",
       "      <td>{'min': 51, 'hour': 6, 'mday': 12, 'sec': 48, ...</td>\n",
       "      <td>1299912708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brewbro000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ABV                       name                    style appearance aroma  \\\n",
       "0    5                   Chiostro     Herbed / Spiced Beer          4     4   \n",
       "1   11   Bearded Pat's Barleywine      American Barleywine          4   3.5   \n",
       "2  4.7       Naughty Nellie's Ale  American Pale Ale (APA)        3.5     4   \n",
       "3  4.4            Pilsner Urquell           Czech Pilsener          3     3   \n",
       "4  4.4  Black Sheep Ale (Special)         English Pale Ale          4     3   \n",
       "\n",
       "  overall palate taste                                               text  \\\n",
       "0       4      4     4  Pours a clouded gold with a thin white head. N...   \n",
       "1     3.5    3.5     3  12oz bottle into 8oz snifter.\\t\\tDeep ruby red...   \n",
       "2     3.5    3.5   3.5  First enjoyed at the brewpub about 2 years ago...   \n",
       "3     2.5      3     3  First thing I noticed after pouring from green...   \n",
       "4       3    3.5   2.5  A: pours an amber with a one finger head but o...   \n",
       "\n",
       "                                          timeStruct    timeUnix ageInSeconds  \\\n",
       "0  {'min': 38, 'hour': 3, 'mday': 16, 'sec': 10, ...  1229398690          NaN   \n",
       "1  {'min': 38, 'hour': 23, 'mday': 8, 'sec': 58, ...  1218238738          NaN   \n",
       "2  {'min': 7, 'hour': 18, 'mday': 26, 'sec': 2, '...  1101492422          NaN   \n",
       "3  {'min': 7, 'hour': 1, 'mday': 20, 'sec': 5, 'y...  1308532025  1.20983e+09   \n",
       "4  {'min': 51, 'hour': 6, 'mday': 12, 'sec': 48, ...  1299912708          NaN   \n",
       "\n",
       "    birthdayRaw birthdayUnix gender profileName  \n",
       "0           NaN          NaN    NaN  RblWthACoz  \n",
       "1           NaN          NaN    NaN     BeerSox  \n",
       "2           NaN          NaN   Male  mschofield  \n",
       "3  Aug 10, 1976  2.08508e+08   Male   molegar76  \n",
       "4           NaN          NaN    NaN  Brewbro000  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data400_share/beer.csv\")\n",
    "data.drop('index',axis =1, inplace = True)\n",
    "newCols = [col.split('/')[1] for col in data.columns]\n",
    "data = pd.DataFrame(data.values, columns = newCols).drop(['beerId','brewerId'], axis = 1)\n",
    "train=data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sumReviews'] = train['appearance'] + train['aroma'] + train['overall'] + train['palate'] + train['taste']\n",
    "sumMean = train['sumReviews'].mean()\n",
    "train['sumReviews'] =  train['sumReviews'].astype(float)\n",
    "userSumMean = train.groupby(['profileName'])['sumReviews'].mean().reset_index()\n",
    "userSumMean['userBias'] = userSumMean['sumReviews'] - sumMean\n",
    "train = train.merge(userSumMean, left_on='profileName', right_on='profileName', how='left')\n",
    "train = train.drop(['sumReviews_y','sumReviews_x'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Additional featureW\n",
    "train['word_count'] = train['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "train['char_count'] = train['text'].str.len() ## this also includes spaces\n",
    "train['avg_word_len'] = train['text'].apply(lambda x: avg_word(str(x)))\n",
    "train['stopwords'] = train['text'].apply(lambda x: len([x for x in str(x).split() if x in stop]))\n",
    "train['questions'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '?' in str(x)]))\n",
    "train['ellipses'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '...' in str(x)]))\n",
    "train['exclamations'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '!' in str(x)]))\n",
    "train['plus'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '+' in str(x)]))\n",
    "train['star'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '*' in str(x)]))\n",
    "train['numerics'] = train['text'].apply(lambda x: len([x for x in str(x).split() if x.isdigit()]))\n",
    "train['upper'] = train['text'].str.findall(r'[A-Z]').str.len()\n",
    "train[\"age_years\"] = (train['ageInSeconds']/31536000.0)#.apply(np.floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"timeStruct\"] = train[\"timeStruct\"].apply(lambda x: dict(eval(x)))\n",
    "beerTimeDic = train[\"timeStruct\"]\n",
    "\n",
    "holidays =[\n",
    "  '2012-01-02',\n",
    "  '2012-01-16',\n",
    "  '2012-02-20',\n",
    "  '2012-05-28',\n",
    "  '2012-07-04',\n",
    "  '2012-09-03',\n",
    "  '2012-10-08',\n",
    "  '2012-11-12',\n",
    "  '2012-11-22',\n",
    "  '2012-12-25']\n",
    "\n",
    "ydayHoliday = []\n",
    "for date in holidays:\n",
    "    ydayHoliday.append(date_to_nth_day(date))\n",
    "    \n",
    "weekHoliday = []\n",
    "for day in ydayHoliday:\n",
    "    temp = list(range(day-3,day+3))\n",
    "    temp = [x for x in temp if(x>0 & x<367)]\n",
    "    for x in temp:\n",
    "        weekHoliday.append(x)\n",
    "        \n",
    "train[\"isHolidayWeek\"] = train[\"timeStruct\"].apply(lambda x: 1 if x['yday'] in weekHoliday else 0)\n",
    "train[\"isWeekend\"] = train[\"timeStruct\"].apply(lambda x: 1 if x['wday'] in [4,5,6] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert reviews to lower case\n",
    "train['text'] = train['text'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "\n",
    "# Remove punctuation characters from  text review\n",
    "train['text'] = train['text'].str.replace('[^\\w\\s]','')\n",
    "# Remove stop words\n",
    "train['text'] = train['text'].apply(lambda x: \" \".join(x for x in str(x).split() if x not in stop))\n",
    "\n",
    "# Stem words\n",
    "train['text'] = train['text'].apply((lambda x: \" \".join(porter.stem(x) for x in str(x).split())))\n",
    "\n",
    "# Remove least frequent words\n",
    "l_freq = pd.Series(' '.join(train['text']).split()).value_counts()[-10:]\n",
    "l_freq = list(l_freq.index)\n",
    "train['text'] = train['text'].apply(lambda x: \" \".join(x for x in str(x).split() if x not in l_freq))\n",
    "\n",
    "# Label beer ratings as positive or negative\n",
    "train['target'] = train['overall'].apply(goodRating)\n",
    "train.sort_values(by = 'overall', ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = train['text'].values\n",
    "target = train['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize words from beer rating text\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(text_train)\n",
    "X = cv.transform(text_train)\n",
    "#X_test = cv.transform(reviews_test_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "c_values = np.linspace(.01,1,100)\n",
    "accuracy = []\n",
    "for c in c_values:\n",
    "    lr = LogisticRegression(C=c, solver='liblinear')\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "          # % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    accuracy.append(accuracy_score(y_val, lr.predict(X_val)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C Value: 0.12\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGfZJREFUeJzt3X+QZWV95/H3BxDZLKAuM4uRAYboaDKxLAkdhE25gMYIVgIB3F0QVIwbKuIkuxpIIFq1BqIYAxV1YU1YZVeiCaIpk4lLxC0CkrWCYRBBAUdHVmSYpRzEsBLX4Mh3/7in9Xrp2316zv3RPff9qury3HOee+7zdI987nOe5zknVYUkSbtrr2lXQJK0uhkkkqRODBJJUicGiSSpE4NEktSJQSJJ6sQgkSR1YpBIkjoxSCRJnewz7QpMwpo1a2r9+vXTroYkrSq33377w1W1dqlyMxEk69evZ8uWLdOuhiStKknub1POS1uSpE4MEklSJwaJJKmTsQZJkhOTbE2yLcmFCxw/PMmNSe5KcnOSdX3Hvp/k883P5r79RyT5bJKvJPlIkn3H2QZJ0uLGFiRJ9gauBE4CNgJnJtk4UOwy4JqqegFwMXBp37H/V1UvbH5O7tv/+8AfVtUG4FvA68fVBknS0sbZIzka2FZV91XV48C1wCkDZTYCNzbbNy1w/EckCfAS4GPNrg8CvzyyGkuSlm2cQXII8EDf6+3Nvn53Aqc326cCByQ5qHm9X5ItSW5NMh8WBwH/UFW7FjmnJGmCxhkkWWDf4HN9zweOS3IHcBzwIDAfEodV1RzwKuDdSZ7d8py9D0/ObYJoy86dO3erAZKkpY0zSLYDh/a9Xgfs6C9QVTuq6rSqOhJ4S7Pv0fljzf/eB9wMHAk8DDw9yT7Dztl37quqaq6q5tauXXJhpiRpN40zSG4DNjSzrPYFzgA29xdIsibJfB0uAq5u9j8jyVPnywA/B9xTVUVvLOWVzXteC/zlGNsgSVrC2IKkGcfYBNwA3AtcV1V3J7k4yfwsrOOBrUm+DBwMvL3Z/1PAliR30guOd1bVPc2x3wbenGQbvTGTD4yrDZKkpaX3JX/PNjc3V95rS5KWJ8ntzVj1olzZLknqxCCRJHVikEiSOjFIJEmdGCSSpE4MEklSJwaJJKkTg0SS1IlBIknqxCCRJHVikEiSOjFIJEmdGCSSpE4MEklSJwaJJKkTg0SS1IlBIknqxCCRJHVikEiSOjFIJEmdGCSSpE4MEklSJwaJJKkTg0SS1IlBIknqxCCRJHVikEiSOjFIJEmdGCSSpE7GGiRJTkyyNcm2JBcucPzwJDcmuSvJzUnWDRw/MMmDSa7o23dmki807/lkkjXjbIMkaXFjC5IkewNXAicBG4Ezk2wcKHYZcE1VvQC4GLh04PglwKf7zrkP8B7ghOY9dwGbxtMCSVIb4+yRHA1sq6r7qupx4FrglIEyG4Ebm+2b+o8nOQo4GPhUX/k0P/88SYADgR3jqb4kqY1xBskhwAN9r7c3+/rdCZzebJ8KHJDkoCR7AZcDF/QXrqrvAW8AvkAvQDYCH1jow5Ocm2RLki07d+7s2hZJ0hDjDJIssK8GXp8PHJfkDuA44EFgF3AecH1V9QcRSZ5CL0iOBJ5F79LWRQt9eFVdVVVzVTW3du3aTg2RJA23zxjPvR04tO/1OgYuQ1XVDuA0gCT7A6dX1aNJjgVenOQ8YH9g3ySPAX/evO+rzXuuA540iC9JmpxxBsltwIYkR9DraZwBvKq/QDPj6pGqeoJez+JqgKo6q6/MOcBcVV2Y5FnAxiRrq2on8DLg3jG2QZK0hLFd2qqqXfRmVN1A7z/211XV3UkuTnJyU+x4YGuSL9MbWH/7EufcAfwucEuSu4AXAu8YUxMkSS2kanDYYs8zNzdXW7ZsmXY1JGlVSXJ7Vc0tVc6V7ZKkTgwSSVInBokkqRODRJLUiUGyCjz06He57IatPPTod6ddFUl6EoNkFfjQrfdzxU3b+NCt90+7KpL0JAbJFLTpYfSXOfuYw9l0wnM4+5jDJ1hLSWrHIJmCNj2M/jLPfNp+nP/y5/HMp+03wVpKUjvjvEWKhpjvWSzWwxhW5qFHv8uHbr3/B/vntw0ZSdNikEzBfA9jd8rM91TmzW8vdT5JGheDZMr6exhtehUL9VQcO5E0TQbJlPX3MNr0KgZ7KvZEJE2bQTJGbXobbcZLJGklc9bWGLWZneWMLEmrnUEyRpNc/9G/7mSUK+FdVS9pKV7aGqM2s7NGZVyzuZY7hiNp9hgkE9JmvGS5M7j6DZvNtdg5h61J6d92DEfSUgySCWnzzb7Lt/9hs7kuu2Hr0HMO68X0b5//8ufZE5G0KINkQrqsZh/l5/b3QpZak7JYPbr0niTtWXxm+4yZ76FsOuE5nXoaozqPpJWr7TPb7ZHMmC69nmG9GXsn0mxz+u+M6bJuZdgdiX1eijTb7JGotWG9mS69E3sz0upnj0StDevNdOmd2JuRVj97JBqp5fZOHGuRVj97JBqp5fZOHGuRVj97JCPmt+ofavOUx/7fkb0TaXWyRzJifqv+oWFjKsN+R/ZOpNVprD2SJCcC7wH2Bt5fVe8cOH44cDWwFngEOLuqtvcdPxC4F/h4VW1q9u0LXAEcDzwBvKWq/nyc7VgO7021sKVW1A/y9yitHmNb2Z5kb+DLwMuA7cBtwJlVdU9fmY8Cn6iqDyZ5CfC6qnp13/H30IRMX5D8LrB3Vb01yV7Av6iqhxeriyvbp8+V8NLq03Zl+zgvbR0NbKuq+6rqceBa4JSBMhuBG5vtm/qPJzkKOBj41MB7fgW4FKCqnlgqRCbBZ3YsrcuzWfz9SivbOIPkEOCBvtfbm3397gROb7ZPBQ5IclDT07gcuKC/cJKnN5uXJPlcko8mOXj0VV8er+cvbVQr6iWtPOMcI8kC+wavo50PXJHkHOAW4EFgF3AecH1VPZD8yGn2AdYBn6mqNyd5M3AZ8GoGJDkXOBfgsMMO69aSJXg9f7z8/Uor2zjHSI4F3lZVL29eXwRQVZcOKb8/8KWqWpfkw8CL6Q2m7w/sC/wX4CLgMeCAqnoiyaHAJ6vqpxeri2MkkrR8K2GM5DZgQ5IjmplWZwCb+wskWdNcxoJeSFwNUFVnVdVhVbWeXq/lmqq6sHqp91f0ZmwBvBS4B80Ux0yklWVsQVJVu4BNwA30pvBeV1V3J7k4yclNseOBrUm+TG9g/e0tTv3bwNuS3EXvktZvjrzyWtEcM5FWliUvbSXZBHy4qr41mSqNnpe29iyuepcmY5SXtp4J3JbkuiQnZmD0W5q0LjPAJI3ekkFSVW8FNgAfAM4BvpLkHUmePea6SZJWgVZjJM0g90PNzy7gGcDHkrxrjHWTJK0CS64jSfIbwGuBh4H3AxdU1fea2VZfAX5rvFWUJK1kbRYkrgFOq6ofmSLTrOP4xfFUS5K0WrS5tHU9vTvzApDkgCQvAqiqe8dVMUnS6tAmSN5HbzX5vH9s9kmS1CpIUn2LTarqCXyyoiSp0SZI7kvyG0me0vz8B+C+cVdMkrQ6tAmSXwP+Fb07824HXkRzV11p2rzvljR9S16iqqpv0LvhorTizN93C/DJi9KUtFlHsh/weuCngR/ck6KqfmWM9VrxvN/TytD/rJL+vwng30eakDaD5n8CfAl4OXAxcBa9u/nONL8Jrwzz992CHz4Xfp5/H2ky2gTJc6rq3yQ5pao+mORP6d0afqb51L6VZ6G/iX8fafza3Eb+76vq6CS30HsE7kPA31fVT0yigqPgbeQlaflGeRv5q5I8A3grvScc3gP8fsf6SRPTP7PLWV7S6C16aau5MeP/bR5qdQuwanoh0rz+8Sxw7EQatUWDpLkx4ybgugnVRxq55Y6dDJuR50w9aWFtBtv/Z5LzgY/Qu88WAFX1yPC3SCtH/8wuWLonMmxGnjP1pIW1CZL59SJv7NtXzNhlLr+Nzo5ha1NcsyItrM3K9iMmUZGVzm+js2PY2pTzX/4816xIC2izsv01C+2vqmtGX52Vy3Uje542vYphf/c24y72YjUr2lza+tm+7f2AlwKfA2YqSAavs2v1azOba9jfvc24i71YzYo2l7Z+vf91kqfRu22KtKqNYyX8sDGVwWP2ULQn2Z0HVH0H2DDqikiTttzZXG0M9kKc9aVZ0GaM5K/ozdKC3kr4jbiuRFrQYmNpjrNpT9XmXlvH9b3cBdxfVdvHWqsR815bkrR8o7zX1teBz1bVp6vqM8A3k6zvWD9ppnn/L+1J2gTJR4En+l5/v9m3pCQnJtmaZFuSCxc4fniSG5PcleTmJOsGjh+Y5MEkVyzw3s1JvtimHtJKMz9e8qFb7/+RbWk1ajPYvk9VPT7/oqoeT7LvUm9KsjdwJfAyes96vy3J5qq6p6/YZcA1zXNOXgJcCry67/glwKcXOPdpwGMt6i6tSMNmjI1qZtewNTLDtp1Fpi7aBMnOJCdX1WaAJKcAD7d439HAtqq6r3nftcAp9G5DP28j8KZm+ybgL+YPJDkKOBj4JDDXt39/4M3AuTjor1Vq2IyxwZX0u2vYGplh284iUxdtguTXgA/3XV7aDiy42n3AIcADfa+3Ay8aKHMncDrwHuBU4IAkBwHfAi6n1zt56cB7LmmOfadFHaRVpcvMrsXWsLTdlnZHmwWJXwWOaXoCqapvtzx3FjrdwOvzgSuSnEPveScP0psZdh5wfVU9kPzwNEleSO/Rv29aasA/ybn0ei0cdthhLassTVeXOygstoalzba0u5YcbE/yjiRPr6rHqurbSZ6R5PdanHs7cGjf63XAjv4CVbWjqk6rqiOBtzT7HgWOBTYl+Rq9cZTXJHlns/+oZv//Ap6b5OaFPryqrqqquaqaW7t2bYvqSivLsNlcw2Z8nX3M4Ww64Tm73Ztx5ph2V5tLWydV1e/Mv6iqbyV5Bb1H7y7mNmBDkiPo9TTOAF7VXyDJGuCRqnoCuAi4uvmMs/rKnAPMVdX8rK/3NfvXA5+oquNbtEFaddo8FwUY2gsZxWdJbbQJkr2TPLWq/gkgyT8DnrrUm6pqV/N0xRuAvYGrq+ruJBcDW5rB++OBS5MUvUtbbxx6QmnGtHkuymDZUX+Ws7nURpuV7b8FnAz8t2bX64DNVfWuMddtZFzZrtVufjbXphOeM/YewyQ/Sytb25XtbQbb35XkLuDn6Q2gfxJwmoc0QZO8T5e9Ey1Xm5XtAA/RW91+Or3puPeOrUaSnmR+Ntck/mPe/1muulcbQ3skSZ5Lb4D8TOCbwEfoXQo7YUJ1kzRlPlNFbSx2aetLwN8Cv1RV2wCSvGmR8pL2MIPrWpzdpYUsFiSn0+uR3JTkk8C1LLzIUNKMcPxECxk6RlJVH6+qfwf8JHAzvXtiHZzkfUl+YUL1k7SCOH6ihSw52F5V/1hVH66qX6S3Ov3zwJNuCS9ptvSvpB+22t4V87NhWc9sr6pHgD9ufiTNsP7xk/67FoN3GJ41ywoSSVpIm7sND3tGyp48vjIr40gGiaTOhj1fpX97WK9lT+6pzMosN4NE0kSM4x5hk9CmJzWszKzMcjNIJE3EYr2WlWyxuy23KTPqp1+uRAaJpKlq83z5aX6DH9aTWu4dmcfVO1kJvz+DRNJUtXm+/DS/wQ/rSQ32MJbqbQ2b5da1bSvh92eQSJqq5c74mkTvpM3ndbkj87DeCQzvUbQZhxk8/+7Wb7kMEklTtdwZX5PonbSZbTVY7+XYnTU4bZ+MOY1xKINE0oo37Nt/1/GB5XzLH5e2PYqVPOttySck7gl8QqK0Z+p/miOw4PZi38qHvX9Pm1W1u0b2hERJWkmWM1tqofGV5c620tIMEkmryuD4xXLHV9q+X+0ZJJJWleWOXwwbY7DnMTqOkUiSFtR2jGTJ55FIkrQYg0SS1IlBIknqxCCRJHVikEiSOjFIJEmdGCSSpE7GGiRJTkyyNcm2JBcucPzwJDcmuSvJzUnWDRw/MMmDSa5oXv9Ykv+R5EtJ7k7yznHWX5K0tLEFSZK9gSuBk4CNwJlJNg4Uuwy4pqpeAFwMXDpw/BLg04PvqaqfBI4Efi7JSSOvvCSptXH2SI4GtlXVfVX1OHAtcMpAmY3Ajc32Tf3HkxwFHAx8an5fVX2nqm5qth8HPgf8SC9GkjRZ4wySQ4AH+l5vb/b1uxM4vdk+FTggyUFJ9gIuBy4YdvIkTwd+iR8G0eDxc5NsSbJl586du9kESdJSxhkkWWDf4I29zgeOS3IHcBzwILALOA+4vqoeYAFJ9gH+DHhvVd23UJmquqqq5qpqbu3atbvbBknSEsZ599/twKF9r9cBO/oLVNUO4DSAJPsDp1fVo0mOBV6c5Dxgf2DfJI9V1fyA/VXAV6rq3WOs/8SfEy1Jq9E4g+Q2YEOSI+j1NM4AXtVfIMka4JGqegK4CLgaoKrO6itzDjA3HyJJfg94GvDvx1h3oN1zmyVp1o0tSKpqV5JNwA3A3sDVVXV3kouBLVW1GTgeuDRJAbcAb1zsnM304LcAXwI+lwTgiqp6/zja4HMLJGlpPo9EkrQgn0ciSZoIg0SS1IlBIknqxCCRJHVikEiSOjFIJEmdGCSSpE4MEklSJwaJJKkTg0SS1IlBIknqxCCRJHVikEiSOjFIJEmdGCSSpE4MEklSJwaJJKkTg0SS1IlBIknqxCCRJHVikEiSOjFIJEmdGCSSpE4MEklSJwaJJKkTg0SS1IlBIknqxCCRJHUy1iBJcmKSrUm2JblwgeOHJ7kxyV1Jbk6ybuD4gUkeTHJF376jknyhOed7k2ScbZAkLW5sQZJkb+BK4CRgI3Bmko0DxS4DrqmqFwAXA5cOHL8E+PTAvvcB5wIbmp8TR1x1SdIyjLNHcjSwraruq6rHgWuBUwbKbARubLZv6j+e5CjgYOBTfft+HDiwqv6uqgq4Bvjl8TVBkrSUcQbJIcADfa+3N/v63Qmc3myfChyQ5KAkewGXAxcscM7tS5xTkjRB4wyShcYuauD1+cBxSe4AjgMeBHYB5wHXV9UDA+XbnLNXMDk3yZYkW3bu3Lm8mkuSWttnjOfeDhza93odsKO/QFXtAE4DSLI/cHpVPZrkWODFSc4D9gf2TfIY8J7mPEPP2Xfuq4CrAObm5hYMG0lSd+MMktuADUmOoNfTOAN4VX+BJGuAR6rqCeAi4GqAqjqrr8w5wFxVXdi8/naSY4DPAq8B/vMY2yBJWsLYLm1V1S5gE3ADcC9wXVXdneTiJCc3xY4Htib5Mr2B9be3OPUbgPcD24CvAn896rpLktpLb/LTnm1ubq62bNky7WpI0qqS5PaqmluqnCvbJUmdGCSSpE4MEklSJwaJJKkTg0SS1IlBIknqxCCRJHVikEiSOjFIJEmdGCSSpE4MEklSJwaJJKkTg0SS1IlBIknqxCCRJHVikEiSOjFIJEmdzMQTEpPsBO5fxlvWAA+PqTor2Sy22zbPhllsM3Rv9+FVtXapQjMRJMuVZEubx0vuaWax3bZ5Nsxim2Fy7fbSliSpE4NEktSJQbKwq6ZdgSmZxXbb5tkwi22GCbXbMRJJUif2SCRJncx0kCQ5McnWJNuSXLjA8acm+Uhz/LNJ1k++lqPVos1vTnJPkruS3Jjk8GnUc9SWandfuVcmqSSrfoZPmzYn+bfN3/vuJH866TqOWot/34cluSnJHc2/8VdMo56jlOTqJN9I8sUhx5Pkvc3v5K4kPzPySlTVTP4AewNfBX4C2Be4E9g4UOY84I+a7TOAj0y73hNo8wnAjzXbb1jtbW7b7qbcAcAtwK3A3LTrPYG/9QbgDuAZzet/Oe16T6DNVwFvaLY3Al+bdr1H0O5/DfwM8MUhx18B/DUQ4Bjgs6Ouwyz3SI4GtlXVfVX1OHAtcMpAmVOADzbbHwNemiQTrOOoLdnmqrqpqr7TvLwVWDfhOo5Dm781wCXAu4DvTrJyY9Kmzb8KXFlV3wKoqm9MuI6j1qbNBRzYbD8N2DHB+o1FVd0CPLJIkVOAa6rnVuDpSX58lHWY5SA5BHig7/X2Zt+CZapqF/AocNBEajcebdrc7/X0vsmsdku2O8mRwKFV9YlJVmyM2vytnws8N8lnktya5MSJ1W482rT5bcDZSbYD1wO/PpmqTdVy/3+/bPuM8mSrzEI9i8EpbG3KrCat25PkbGAOOG6sNZqMRdudZC/gD4FzJlWhCWjzt96H3uWt4+n1PP82yfOr6h/GXLdxadPmM4H/XlWXJzkW+JOmzU+Mv3pTM/b/js1yj2Q7cGjf63U8uZv7gzJJ9qHXFV6sC7nStWkzSX4eeAtwclX904TqNk5LtfsA4PnAzUm+Ru868uZVPuDe9t/3X1bV96rqfwNb6QXLatWmza8HrgOoqr8D9qN3P6o9Wav/33cxy0FyG7AhyRFJ9qU3mL55oMxm4LXN9iuBv6lm9GqVWrLNzSWeP6YXIqv9mvm8RdtdVY9W1ZqqWl9V6+mNDZ1cVVumU92RaPPv+y/oTa4gyRp6l7rum2gtR6tNm78OvBQgyU/RC5KdE63l5G0GXtPM3joGeLSq/s8oP2BmL21V1a4km4Ab6M32uLqq7k5yMbClqjYDH6DX9d1GrydyxvRq3F3LNv8BsD/w0WZewder6uSpVXoEWrZ7j9KyzTcAv5DkHuD7wAVV9c3p1bqblm3+TeC/JnkTvcs756zyL4ck+TN6lyfXNGM//wl4CkBV/RG9saBXANuA7wCvG3kdVvnvUJI0ZbN8aUuSNAIGiSSpE4NEktSJQSJJ6sQgkSR1YpBIU5DkmUmuTfLV5u671yd57rTrJe0Og0SasObGnx8Hbq6qZ1fVRuB3gIOnWzNp98zsgkRpik4AvtcsFgOgqj4/xfpIndgjkSbv+cDt066ENCoGiSSpE4NEmry7gaOmXQlpVAwSafL+Bnhqkl+d35HkZ5PsCc9+0Qzypo3SFCR5FvBuej2T7wJfA/5jVX1lmvWSdodBIknqxEtbkqRODBJJUicGiSSpE4NEktSJQSJJ6sQgkSR1YpBIkjoxSCRJnfx/cHieyu2yRqEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimize the C hyperparameter for regularization \n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.scatter(c_values, accuracy, s = 1.2)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('C')\n",
    "best_c = c_values[accuracy.index(max(accuracy))]\n",
    "print('Best C Value:', best_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.12, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = LogisticRegression(C = best_c, solver = 'liblinear')\n",
    "final_model.fit(X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('easi', 1.2375258032894554)\n",
      "('awesom', 0.84146245928718055)\n",
      "('tasti', 0.76317543146134426)\n",
      "('rye', 0.74469787152053779)\n",
      "('smooth', 0.74377309257974245)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print (best_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('drain', -1.1792084034512553)\n",
      "('drainpour', -1.0380712114393462)\n",
      "('chemic', -0.8897327034554835)\n",
      "('worst', -0.88943867939839394)\n",
      "('aw', -0.87740353150414685)\n"
     ]
    }
   ],
   "source": [
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['avg_sent'] = train['text'].apply(avgSentiment, args = (feature_to_coef,))\n",
    "train['#pos_words'] = train['text'].apply(posWords, args = (feature_to_coef,))\n",
    "train['#neg_words'] = train['text'].apply(negWords, args = (feature_to_coef,))\n",
    "train['#pos/#neg'] = train['#pos_words']/train['#neg_words']\n",
    "# Some values turn to infinite due to 0 divison, its fixed below\n",
    "mask = train['#pos/#neg'] != np.inf\n",
    "# Make values that infinite equal to the # pos words\n",
    "train.loc[~mask, '#pos/#neg' ] = train.loc[~mask, '#pos_words']\n",
    "\n",
    "# Gender encoding\n",
    "train['gender'] = train['gender'].fillna('N/A')\n",
    "train = train.join(pd.get_dummies(train['gender']))\n",
    "train.drop('gender', axis =1, inplace = True)\n",
    "\n",
    "# Style encoding \n",
    "train = train.join(pd.get_dummies(train['style']))\n",
    "train.drop('style', axis = 1, inplace = True)\n",
    "\n",
    "# Convert ageInSeconds to years, unknown age set to 0\n",
    "# minutes, hours, days, weeks, years\n",
    "train['ageInSeconds'] = train['ageInSeconds'].fillna(0)\n",
    "train['age'] = train['ageInSeconds'].astype(float) / 60 / 60 / 24 / 7 / 52\n",
    "train['age'] = train['age'].apply(lambda x: math.floor(x))\n",
    "# Convert all columns that have been transformed and will no longer be used\n",
    "# Drop beer name, cannot one hot encode due to huge dimensionality increase\n",
    "# Drop profile name\n",
    "train.drop(['timeStruct','timeUnix','birthdayRaw','birthdayUnix','ageInSeconds',\n",
    "           'profileName'],\n",
    "           axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "num_cols = ['ABV',\n",
    " 'appearance',\n",
    " 'aroma',\n",
    " 'overall',\n",
    " 'palate',\n",
    " 'taste',\n",
    " 'age',\n",
    " 'userBias',\n",
    " 'word_count',\n",
    " 'char_count',\n",
    " 'avg_word_len',\n",
    " 'stopwords',\n",
    " 'questions',\n",
    " 'ellipses',\n",
    " 'exclamations',\n",
    " 'plus',\n",
    " 'star',\n",
    " 'numerics',\n",
    " 'upper',\n",
    " 'age_years',\n",
    " 'avg_sent',\n",
    " '#pos_words',\n",
    " '#neg_words',\n",
    " '#pos/#neg']\n",
    "\n",
    "for col in num_cols:    \n",
    "    minimum = train[col].min()\n",
    "    maximum = train[col].max()\n",
    "    train[col] = (train[col]-(minimum-.00000001)) / (maximum-minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:18: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n"
     ]
    }
   ],
   "source": [
    "open_beer = pd.read_csv('open-beer-database.csv', sep = ';').rename(columns = {'Name':'name'})\n",
    "open_beer = open_beer[['name','Country']]\n",
    "open_beer.drop_duplicates(inplace = True)\n",
    "one_hot = pd.get_dummies(open_beer['Country'])\n",
    "open_beer.drop('Country', axis = 1, inplace = True)\n",
    "open_beer = open_beer.join(one_hot)\n",
    "beer_names = list(set(open_beer['name'].values))\n",
    "\n",
    "# Compress one hot encoding to get one beer and all locations into one row\n",
    "beer_locs = []\n",
    "for beer in beer_names:\n",
    "    cur_beer = open_beer[open_beer['name'] == beer]\n",
    "    t = np.zeros(one_hot.shape[1])\n",
    "    for row in cur_beer.iterrows():\n",
    "        index, data = row\n",
    "        t = np.add( t, np.array(data)[1:])\n",
    "    beer_locs.append(t)   \n",
    "final_hot = pd.DataFrame.from_items(zip(one_hot.columns, np.array(beer_locs).T))\n",
    "final_hot['name'] = beer_names\n",
    "\n",
    "merged = pd.merge(train, final_hot, on = 'name', how = 'left')\n",
    "merged.drop(['name','text','target'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('train.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABV</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>overall</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>userBias</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>...</th>\n",
       "      <th>Slovakia</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Sri Lanka</th>\n",
       "      <th>Sweden</th>\n",
       "      <th>Switzerland</th>\n",
       "      <th>Taiwan, Province of China</th>\n",
       "      <th>Thailand</th>\n",
       "      <th>Togo</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <th>United States</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0920139</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.135916</td>\n",
       "      <td>0.31262</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 185 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ABV appearance aroma overall palate  taste  userBias  word_count  \\\n",
       "0  0.0920139        0.7  0.75       1   0.75  0.875     0.745    0.135593   \n",
       "\n",
       "   char_count  avg_word_len      ...        Slovakia  Spain  Sri Lanka  \\\n",
       "0    0.135916       0.31262      ...               0      0          0   \n",
       "\n",
       "   Sweden  Switzerland  Taiwan, Province of China  Thailand  Togo  \\\n",
       "0       0            0                          0         0     0   \n",
       "\n",
       "  United Kingdom  United States  \n",
       "0              0              0  \n",
       "\n",
       "[1 rows x 185 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
