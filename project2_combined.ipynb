{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from datetime import datetime\n",
    "\n",
    "def goodRating(row):\n",
    "    return row >= 3\n",
    "\n",
    "def avgSentiment(row, w_dict):\n",
    "    s = 0\n",
    "    tokens = row.split()\n",
    "    for t in tokens:\n",
    "         s += w_dict[t]\n",
    "    return s/len(tokens)\n",
    "\n",
    "def avgSentiment(row, w_dict):\n",
    "    s = 0\n",
    "    count = 0\n",
    "    tokens = row.split()\n",
    "    for t in tokens:\n",
    "        try:\n",
    "            s += w_dict[t]\n",
    "            count += 1\n",
    "        except:\n",
    "            continue\n",
    "    return s/count\n",
    "\n",
    "def posWords(row, w_dict):\n",
    "    numWords = 0\n",
    "    tokens = row.split()\n",
    "    for t in tokens:\n",
    "        try: \n",
    "            if w_dict[t] > 0:\n",
    "                numWords += 1\n",
    "        except:\n",
    "            continue\n",
    "    return numWords\n",
    "\n",
    "def negWords(row, w_dict):\n",
    "    numWords = 0\n",
    "    tokens = row.split()\n",
    "    for t in tokens:\n",
    "        try: \n",
    "            if w_dict[t] < 0:\n",
    "                numWords += 1\n",
    "        except:\n",
    "            continue\n",
    "    return numWords\n",
    "\n",
    "def date_to_nth_day(date, format='%Y-%m-%d'):\n",
    "    date = pd.to_datetime(date, format=format)\n",
    "    new_year_day = pd.Timestamp(year=date.year, month=1, day=1)\n",
    "    return (date - new_year_day).days + 1\n",
    "\n",
    "# Porter stemmer for text stemming\n",
    "porter = PorterStemmer()\n",
    "\n",
    "stop = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \n",
    "        \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \n",
    "        \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \n",
    "        \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \n",
    "        \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \n",
    "        \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \n",
    "        \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \n",
    "        \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \n",
    "        \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \n",
    "        \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \n",
    "        \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \n",
    "        \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \n",
    "        \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "def avg_word(sentence):\n",
    "    words = sentence.split()\n",
    "    return (sum(len(word) for word in words)/len(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABV</th>\n",
       "      <th>name</th>\n",
       "      <th>style</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>overall</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>text</th>\n",
       "      <th>timeStruct</th>\n",
       "      <th>timeUnix</th>\n",
       "      <th>ageInSeconds</th>\n",
       "      <th>birthdayRaw</th>\n",
       "      <th>birthdayUnix</th>\n",
       "      <th>gender</th>\n",
       "      <th>profileName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Chiostro</td>\n",
       "      <td>Herbed / Spiced Beer</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Pours a clouded gold with a thin white head. N...</td>\n",
       "      <td>{'min': 38, 'hour': 3, 'mday': 16, 'sec': 10, ...</td>\n",
       "      <td>1229398690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RblWthACoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>Bearded Pat's Barleywine</td>\n",
       "      <td>American Barleywine</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>12oz bottle into 8oz snifter.\\t\\tDeep ruby red...</td>\n",
       "      <td>{'min': 38, 'hour': 23, 'mday': 8, 'sec': 58, ...</td>\n",
       "      <td>1218238738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BeerSox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>Naughty Nellie's Ale</td>\n",
       "      <td>American Pale Ale (APA)</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>First enjoyed at the brewpub about 2 years ago...</td>\n",
       "      <td>{'min': 7, 'hour': 18, 'mday': 26, 'sec': 2, '...</td>\n",
       "      <td>1101492422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>mschofield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4</td>\n",
       "      <td>Pilsner Urquell</td>\n",
       "      <td>Czech Pilsener</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>First thing I noticed after pouring from green...</td>\n",
       "      <td>{'min': 7, 'hour': 1, 'mday': 20, 'sec': 5, 'y...</td>\n",
       "      <td>1308532025</td>\n",
       "      <td>1.20983e+09</td>\n",
       "      <td>Aug 10, 1976</td>\n",
       "      <td>2.08508e+08</td>\n",
       "      <td>Male</td>\n",
       "      <td>molegar76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.4</td>\n",
       "      <td>Black Sheep Ale (Special)</td>\n",
       "      <td>English Pale Ale</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>A: pours an amber with a one finger head but o...</td>\n",
       "      <td>{'min': 51, 'hour': 6, 'mday': 12, 'sec': 48, ...</td>\n",
       "      <td>1299912708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brewbro000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ABV                       name                    style appearance aroma  \\\n",
       "0    5                   Chiostro     Herbed / Spiced Beer          4     4   \n",
       "1   11   Bearded Pat's Barleywine      American Barleywine          4   3.5   \n",
       "2  4.7       Naughty Nellie's Ale  American Pale Ale (APA)        3.5     4   \n",
       "3  4.4            Pilsner Urquell           Czech Pilsener          3     3   \n",
       "4  4.4  Black Sheep Ale (Special)         English Pale Ale          4     3   \n",
       "\n",
       "  overall palate taste                                               text  \\\n",
       "0       4      4     4  Pours a clouded gold with a thin white head. N...   \n",
       "1     3.5    3.5     3  12oz bottle into 8oz snifter.\\t\\tDeep ruby red...   \n",
       "2     3.5    3.5   3.5  First enjoyed at the brewpub about 2 years ago...   \n",
       "3     2.5      3     3  First thing I noticed after pouring from green...   \n",
       "4       3    3.5   2.5  A: pours an amber with a one finger head but o...   \n",
       "\n",
       "                                          timeStruct    timeUnix ageInSeconds  \\\n",
       "0  {'min': 38, 'hour': 3, 'mday': 16, 'sec': 10, ...  1229398690          NaN   \n",
       "1  {'min': 38, 'hour': 23, 'mday': 8, 'sec': 58, ...  1218238738          NaN   \n",
       "2  {'min': 7, 'hour': 18, 'mday': 26, 'sec': 2, '...  1101492422          NaN   \n",
       "3  {'min': 7, 'hour': 1, 'mday': 20, 'sec': 5, 'y...  1308532025  1.20983e+09   \n",
       "4  {'min': 51, 'hour': 6, 'mday': 12, 'sec': 48, ...  1299912708          NaN   \n",
       "\n",
       "    birthdayRaw birthdayUnix gender profileName  \n",
       "0           NaN          NaN    NaN  RblWthACoz  \n",
       "1           NaN          NaN    NaN     BeerSox  \n",
       "2           NaN          NaN   Male  mschofield  \n",
       "3  Aug 10, 1976  2.08508e+08   Male   molegar76  \n",
       "4           NaN          NaN    NaN  Brewbro000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data400_share/beer.csv\")\n",
    "data.drop('index',axis =1, inplace = True)\n",
    "newCols = [col.split('/')[1] for col in data.columns]\n",
    "data = pd.DataFrame(data.values, columns = newCols).drop(['beerId','brewerId'], axis = 1)\n",
    "train=data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sumReviews'] = train['appearance'] + train['aroma'] + train['overall'] + train['palate'] + train['taste']\n",
    "sumMean = train['sumReviews'].mean()\n",
    "train['sumReviews'] =  train['sumReviews'].astype(float)\n",
    "userSumMean = train.groupby(['profileName'])['sumReviews'].mean().reset_index()\n",
    "userSumMean['userBias'] = userSumMean['sumReviews'] - sumMean\n",
    "train = train.merge(userSumMean, left_on='profileName', right_on='profileName', how='left')\n",
    "train = train.drop(['sumReviews_y','sumReviews_x'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Additional featureW\n",
    "train['word_count'] = train['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "train['char_count'] = train['text'].str.len() ## this also includes spaces\n",
    "train['avg_word_len'] = train['text'].apply(lambda x: avg_word(str(x)))\n",
    "train['stopwords'] = train['text'].apply(lambda x: len([x for x in str(x).split() if x in stop]))\n",
    "train['questions'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '?' in str(x)]))\n",
    "train['ellipses'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '...' in str(x)]))\n",
    "train['exclamations'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '!' in str(x)]))\n",
    "train['plus'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '+' in str(x)]))\n",
    "train['star'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '*' in str(x)]))\n",
    "train['numerics'] = train['text'].apply(lambda x: len([x for x in str(x).split() if x.isdigit()]))\n",
    "train['upper'] = train['text'].str.findall(r'[A-Z]').str.len()\n",
    "train[\"age_years\"] = (train['ageInSeconds']/31536000.0)#.apply(np.floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"timeStruct\"] = train[\"timeStruct\"].apply(lambda x: dict(eval(x)))\n",
    "beerTimeDic = train[\"timeStruct\"]\n",
    "\n",
    "holidays =[\n",
    "  '2012-01-02',\n",
    "  '2012-01-16',\n",
    "  '2012-02-20',\n",
    "  '2012-05-28',\n",
    "  '2012-07-04',\n",
    "  '2012-09-03',\n",
    "  '2012-10-08',\n",
    "  '2012-11-12',\n",
    "  '2012-11-22',\n",
    "  '2012-12-25']\n",
    "\n",
    "ydayHoliday = []\n",
    "for date in holidays:\n",
    "    ydayHoliday.append(date_to_nth_day(date))\n",
    "    \n",
    "weekHoliday = []\n",
    "for day in ydayHoliday:\n",
    "    temp = list(range(day-3,day+3))\n",
    "    temp = [x for x in temp if(x>0 & x<367)]\n",
    "    for x in temp:\n",
    "        weekHoliday.append(x)\n",
    "        \n",
    "train[\"isHolidayWeek\"] = train[\"timeStruct\"].apply(lambda x: 1 if x['yday'] in weekHoliday else 0)\n",
    "train[\"isWeekend\"] = train[\"timeStruct\"].apply(lambda x: 1 if x['wday'] in [4,5,6] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert reviews to lower case\n",
    "train['text'] = train['text'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "\n",
    "# Remove punctuation characters from  text review\n",
    "train['text'] = train['text'].str.replace('[^\\w\\s]','')\n",
    "# Remove stop words\n",
    "train['text'] = train['text'].apply(lambda x: \" \".join(x for x in str(x).split() if x not in stop))\n",
    "\n",
    "# Stem words\n",
    "train['text'] = train['text'].apply((lambda x: \" \".join(porter.stem(x) for x in str(x).split())))\n",
    "\n",
    "# Remove least frequent words\n",
    "l_freq = pd.Series(' '.join(train['text']).split()).value_counts()[-10:]\n",
    "l_freq = list(l_freq.index)\n",
    "train['text'] = train['text'].apply(lambda x: \" \".join(x for x in str(x).split() if x not in l_freq))\n",
    "\n",
    "# Label beer ratings as positive or negative\n",
    "train['target'] = train['overall'].apply(goodRating)\n",
    "train.sort_values(by = 'overall', ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = train['text'].values\n",
    "target = train['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize words from beer rating text\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(text_train)\n",
    "X = cv.transform(text_train)\n",
    "#X_test = cv.transform(reviews_test_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "c_values = np.linspace(.01,1,100)\n",
    "accuracy = []\n",
    "for c in c_values:\n",
    "    lr = LogisticRegression(C=c, solver='liblinear')\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "          # % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    accuracy.append(accuracy_score(y_val, lr.predict(X_val)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C Value: 0.09\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGiNJREFUeJzt3X3QZnV93/H3RwhiyoOG3UBkyS4J+LA1NsodRB27UJoITgMBkhQUFSVhFLedmGADNZ2moCGxMFUrY7KtjKJJEJqarikJOitoxhGHGxF01dUVRZbVcRWlGgZxw7d/XGfJxcX9cO4917nup/drZofz8Dvn+v7ua9nv/Tu/h5OqQpKk/fWkxQ5AkrS8mUgkSZ2YSCRJnZhIJEmdmEgkSZ2YSCRJnZhIJEmdmEgkSZ2YSCRJnRy42AFMwpo1a2rDhg2LHYYkLSt33HHHd6pq7XzlVkUi2bBhA9PT04sdhiQtK0nubVPOR1uSpE5MJJKkTnpNJElOS7Ijyc4kl85wfn2SbUnuTnJrknUj5w9Lcn+Sdw0dOyjJliRfTvKlJOf0WQdJ0tx6SyRJDgCuAU4HNgLnJdk4Uuwq4Lqqei5wOXDlyPkrgI+PHHsz8O2qekZz39HzkqQJ6rNFciKws6ruqapHgOuBM0fKbAS2Ndu3DJ9PcgJwJPCRkWteS5NwqurRqvpOD7FLklrqM5EcDdw3tL+rOTbsLmDfo6mzgEOTHJHkScDVwJuGCyd5arN5RZLPJLkxyZHjD12S1FafiSQzHBt9HeMlwKYkdwKbgPuBvcDFwE1Vdd9I+QOBdcAnq+r5wKcYPB574ocnFyWZTjK9Z8+eDtWQJM2lz3kku4BjhvbXAbuHC1TVbuBsgCSHAOdU1YNJXgi8JMnFwCHAQUl+CFwGPAR8qLnFjcCFM314VW0BtgBMTU35PmFJ6kmfieR24PgkxzJoaZwLvHy4QJI1wANV9SiDJHEtQFW9YqjMBcBUVV3a7H8YOBn4GHAq8IUe6yBJmkdvj7aqai+wGbgZ+CJwQ1VtT3J5kjOaYicDO5J8mUHH+ltb3Pr3gT9McjfwSuD3xh68JKm1VK38pz5TU1PlEimStDBJ7qiqqfnKObNdktSJiUSS1ImJRJLUiYlEktSJiUSS1ImJRJLUiYlEktSJiUSS1ImJRJLUiYlEktSJiUSS1ImJRJLUiYlEktSJiUSS1ImJRJLUiYlEktSJiUSS1ImJRJLUiYlEktSJiUSS1ImJRJLUiYlEktSJiUSS1ImJRJLUiYlEktSJiUSS1ImJRJLUiYlEktSJiUSS1ImJRJLUiYlEktRJr4kkyWlJdiTZmeTSGc6vT7Ityd1Jbk2ybuT8YUnuT/KuGa7dmuTzfcYvSZpfb4kkyQHANcDpwEbgvCQbR4pdBVxXVc8FLgeuHDl/BfDxGe59NvDDsQctSVqwPlskJwI7q+qeqnoEuB44c6TMRmBbs33L8PkkJwBHAh8ZviDJIcDvAm/pKW5J0gL0mUiOBu4b2t/VHBt2F3BOs30WcGiSI5I8CbgaeNMM972iOffQXB+e5KIk00mm9+zZsz/xS5Ja6DORZIZjNbJ/CbApyZ3AJuB+YC9wMXBTVQ0nIpL8InBcVX1ovg+vqi1VNVVVU2vXrt2vCkiS5ndgj/feBRwztL8O2D1coKp2A2fDY4+szqmqB5O8EHhJkouBQ4CDkvwQuBc4IcnXm9h/OsmtVXVyj/WQJM2hz0RyO3B8kmMZtDTOBV4+XCDJGuCBqnoUuAy4FqCqXjFU5gJgqqr2jfp6d3N8A/A3JhFJWly9Pdqqqr3AZuBm4IvADVW1PcnlSc5oip0M7EjyZQYd62/tKx5JUj9SNdptsfJMTU3V9PT0YochSctKkjuqamq+cs5slyR1YiKRJHViIpEkdWIikSR1YiKRJHViIpEkdWIiWWTfevBhrrp5B9968OHFDkWS9ouJZJF94LZ7edctO/nAbfcudiiStF9MJBMy3PIY3j7/pPVsPuU4zj9pva0TSctSn2ttaci+lsc++7YveekzueSlzwTgqpt3PO64JC0HJpIJOf+k9Y/77+j2bGUkaalzrS1J0oxca0uSNBEmEklSJyYSSVInJhJJUicmkiVqtjklCz0uSX0zkSxRs814X+hxSeqb80iWqOE5Jd968GE+cNu9nH/S+lnnmjgHRdJicR7JMrBvxvvmU45zxrukiXEeyRIwrn6L4fW4+ri/JHVhIunRuPotjjr8YC556TM56vCDe7m/JHVhH0mP+u63sF9E0lJgi2TMhh83zdaSGJfZ7t/2kddsS9v7yEzSQtgiGbPh5eIXq2O8bQyzLW0/vG3nvqT5mEjGbCk8bppt6PBRhx8871DiuZa5l6SZOPx3hRsdOuxQYklttR3+a4tkhRttdSy0xTTcggFm3J6tD2i0NSRpZTKRrHD7OuRn259Pl36UpdBfJKl/JhLNqU0/ymwtj7n6aiStHL0O/01yWpIdSXYmuXSG8+uTbEtyd5Jbk6wbOX9YkvuTvKvZ/8kk/zfJl5JsT/LHfcavxw8xnm17tomRbcpIWv56SyRJDgCuAU4HNgLnJdk4Uuwq4Lqqei5wOXDlyPkrgI+PXlNVzwKeB7w4yeljD14LMryEy2xzUNqUkbQ89dkiORHYWVX3VNUjwPXAmSNlNgLbmu1bhs8nOQE4EvjIvmNV9VBV3dJsPwJ8BnhcK0aTZ+tEWt367CM5GrhvaH8X8IKRMncB5wDvAM4CDk1yBPA94GrglcCpM908yVOBX22u1RLRZlTYUphrI2l8+myRZIZjo5NWLgE2JbkT2ATcD+wFLgZuqqr7mEGSA4G/BN5ZVffMUuaiJNNJpvfs2bO/ddACtVkWpu+lYyRN1ryJJMnmJE/bj3vvAo4Z2l8H7B4uUFW7q+rsqnoe8Obm2IPAC4HNSb7OoB/lVSMd61uAr1TV22f78KraUlVTVTW1du3a/Qi/PZ/5S1rN2rRIjgJuT3JDMwprppbGTG4Hjk9ybJKDgHOBrcMFkqxJsi+Gy4BrAarqFVX1s1W1gUGr5bqqurS55i3A4cDvtIyjdz7zl7SazZtIquoPgOOB9wAXAF9J8kdJfn6e6/YCm4GbgS8CN1TV9iSXJzmjKXYysCPJlxl0rL91rns2w4PfzKCT/jNJPpvkt+arQ99me/GU5mdrTlr+Wq+1leRfAK8BTmMwwuok4KNV9R/6C288VvNaW0uda39JS9fYXrWb5N8nuQN4G/BJ4Beq6vXACQxGXEn7bbXOL1lNddXK12b47xrg7Kp6XAdAVT2a5N/0E5ZWi+G1v/a1TmDlr83lOmRaSdp0tt8EPLBvJ8mhSV4AUFVf7CswrT6z9TWtlN/eh+sxW0us7zdVrpSfpZaWNi2SdwPPH9r/hxmOSZ3NtjLxSvntfbQeM7XEoN83Va6Un6WWljaJJDXUI9880nLVYE3MSpkJP1s9JvmmypXys9TSMu+orST/G7iVQSsEBrPOT6mqX+s3tPFx1NbyM9ey87O9bGu43Epbtr5LfWa7ts3PUavbON+Q+DrgncAfMFjiZBtwUbfwpLnN9QhmtpdtDZdbaY9wutRntmvb/BylNuZNJFX1bQaz0qWJmesRzHyPgua7fjnq8pKwhT5Ss6WihWrzaOtg4ELgnwOP/U2qqtf2G9r4+GhLK0nfkziH7w84YXQVG9uEROD9DNbbeimDl0ytA37QLTxp/GYb2jquIa8LHZrb11DbvocOD99/dEh238OTtTy16SM5rqp+I8mZVfW+JH/BYP0saUlp0xfQ5bfqhfYp9NVPM9skzuGY2sTX5v6j19uvopm0SSQ/bv77/STPAb4FbOgtImk/tekL6DL6aaF9CpPop5nk0OG5Pm+hP9eVNqputWvTR/JbwF8BvwC8FzgE+E9V9We9Rzcm9pFonz76F+xTWPjP1cU6l4exDP9t3hXy/6rqe8AngJ8bU3zLnr9RLU9tWgnjGBW1UkaLtTVbqw+Yt7XWpnyb+S+zlVf/5kwkzSz2zcANE4pn2Vhp8xRWi9mWYRm20O92rj6F1WJ/+m32t59ntn6a2cqrf236SD6a5BLggwzW2QKgqh6Y/ZKVb6XNU1jthn/LHVefymq10H6bNuVn+37a3F/9a9NH8rUZDldVLZvHXPaRaD6zPbP3Wf7S4PewOMa2REpVHTuekKSlZb7fcof3/S13cS30e7AlOVnzJpIkr5rpeFVdN/5wpMmZbVn3YW36VNS/hX4P9mFOVps+kl8a2j4YOBX4DGAi0bJma2Pl8rudrHn7SJ5wQXI48P6qOqOfkMbPPhJJWrhxrrU16iHg+P24TpImzjXB+temj+TDDN5DAoPEsxHnlUhaJuwv6V+bPpKrhrb3AvdW1a6e4pGksbK/pH9tEsk3gG9W1cMASZ6SZENVfb3XyCRpDBx51782fSQ3Ao8O7f9jc0ySpFaJ5MCqemTfTrN9UH8hSVJ/fDnX+LV5tLUnyRlVtRUgyZnAd/oNS5L64cu5xq9NInkd8OdJ3tXs7wJmnO0uSUvduF7OpX/SZq2trwInJTmEwQRG39cuadmabdn/4eXsbZ0szLx9JEn+KMlTq+qHVfWDJE9L8pY2N09yWpIdSXYmuXSG8+uTbEtyd5Jbk6wbOX9YkvuHWkMkOSHJ55p7vjNJ2sQiSXM5/6T1bD7luMdaJ/adtNems/30qvr+vp3mbYkvm++iJAcA1wCnM5jEeF6SjSPFrgKuq6rnApcDV46cvwL4+MixdwMXMZhdfzxwWos6SNKc9rVUjjr84Mf6UT5w272LHday0CaRHJDkyft2kjwFePIc5fc5EdhZVfc0I72uB84cKbMR2NZs3zJ8PskJwJHAR4aO/QxwWFV9qgaLhF0H/FqLWCSpNVsnC9MmkXwA2JbkwiQXAh8F3tfiuqOB+4b2dzXHht0FnNNsnwUcmuSI5l3xVwNvmuGew7PqZ7qnJHVi62Rh5k0kVfU24C3Asxm0IP4OaLPWwEx9F6NLDV8CbEpyJ7AJuJ/BMiwXAzdV1X0j5dvcc1AwuSjJdJLpPXv2tAhXkp5ottaJ81H+SZvhvwDfYjC7/TeBrwF/1eKaXcAxQ/vrgN3DBapqN3A2QDMq7JyqejDJC4GXJLkYOAQ4KMkPgXc095n1nkP33gJsgcEy8i3ilaQnGB7lNTyyC3A+SmPWRJLkGcC5wHnAd4EPMhj+e0rLe98OHJ/kWAYtjXOBl498xhrggap6FLgMuBagql4xVOYCYKqqLm32f5DkJODTDOaz/PeW8UhSJ7PNQZlpezWZq0XyJeDvgV+tqp0ASd7Y9sZVtTfJZuBm4ADg2qranuRyYLqZKX8ycGWSAj4BvKHFrV8PvBd4CvC3zR9J6t1sc1BGt1ebWd+QmOQsBq2IFzHoF7ke+J9VdezkwhuPcbwh0VmvktpYSf9WdH5DYlV9qKr+LfAs4FbgjcCRSd6d5FfGFuky4cgNSW2sxn8r2iyR8g/AnzNYb+ungN8ALmVofsdq4MtxJLWxGv+tmPXR1koyjkdbkrTadH60JUlSGyYSSVInJhJJ6slqmfFuIpGknqyWEVxtl0iRJC3QahnBZSKRpJ6MzoRfqXy0JUnqxEQiSROwkjveTSSSNAEruePdPhJJmoDhjveVtLAj2CKRpIlYya/vtUUiSRO20lontkgkacJWWuvERCJJi+j8k9az+ZTjHmudzDayaymP+jKRSNIiats6WcotF/tIJGmJmKvvZCn3q9gikaQlYq7WyVLuV7FFIklL0FwLPi611oktEklagoZbIHOdWwqtE1skkrSMLYWl6k0kkrSMLYWl6n20JUkrxGLNNTGRSNIKsVj9JSaSOSzlmaSSNKrtLPlxM5HMYSmMhpCkthZrNJed7XNYCqMhJGl/TPLfr1RV7x+y2Kampmp6enqxw5CkZSXJHVU1NV85H21JkjrpNZEkOS3JjiQ7k1w6w/n1SbYluTvJrUnWDR2/I8lnk2xP8rqha85L8rnmmr9LsqbPOkiS5tZbIklyAHANcDqwETgvycaRYlcB11XVc4HLgSub498EXlRVvwi8ALg0ydOTHAi8AzilueZuYHNfdZAkza/PFsmJwM6quqeqHgGuB84cKbMR2NZs37LvfFU9UlU/ao4/eSjONH/+WZIAhwG7+6uCJGk+fSaSo4H7hvZ3NceG3QWc02yfBRya5AiAJMckubu5x59U1e6q+jHweuBzDBLIRuA9M314kouSTCeZ3rNnz7jqJEka0WciyQzHRoeIXQJsSnInsAm4H9gLUFX3NY+vjgNeneTIJD/BIJE8D3g6g0dbl8304VW1paqmqmpq7dq1Y6mQJOmJ+pxHsgs4Zmh/HSOPoapqN3A2QJJDgHOq6sHRMkm2Ay8B7m2OfbW55gbgCZ34kqTJ6bNFcjtwfJJjkxwEnAtsHS6QZE2SfTFcBlzbHF+X5CnN9tOAFwM7GLRYNibZ18T4ZeCLPdZBkjSP3lokVbU3yWbgZuAA4Nqq2p7kcmC6qrYCJwNXJingE8AbmsufDVzdHA9wVVV9DiDJfwE+keTHDFooF/RVB0nS/JzZLkmakTPbJUkTYSKRJHViIpEkdWIikSR1YiKRJHViIpEkdWIikSR1YiKRJHViIpEkdWIikSR1YiKRJHViIpEkdWIikSR1YiKRJHViIpEkdWIikSR1YiKRJHViIpEkdWIikSR1YiKRJHViIpEkdWIikSR1YiKRJHViIpEkdWIikSR1YiKRJHViIpEkdWIikSR1YiKRJHViIpEkddJrIklyWpIdSXYmuXSG8+uTbEtyd5Jbk6wbOn5Hks8m2Z7kdUPXHJRkS5IvJ/lSknP6rIMkaW4H9nXjJAcA1wC/DOwCbk+ytaq+MFTsKuC6qnpfkn8FXAm8Evgm8KKq+lGSQ4DPN9fuBt4MfLuqnpHkScBP9VUHSdL8ekskwInAzqq6ByDJ9cCZwHAi2Qi8sdm+BfhrgKp6ZKjMk3l8y+m1wLOaco8C3+kjeElSO30+2joauG9of1dzbNhdwL5HU2cBhyY5AiDJMUnubu7xJ1W1O8lTm7JXJPlMkhuTHNlfFSRJ8+kzkWSGYzWyfwmwKcmdwCbgfmAvQFXdV1XPBY4DXt0kjAOBdcAnq+r5wKcYPB574ocnFyWZTjK9Z8+esVRIkvREfSaSXcAxQ/vrgN3DBapqd1WdXVXPY9D3QVU9OFoG2A68BPgu8BDwoeb0jcDzZ/rwqtpSVVNVNbV27doxVEeSNJM+E8ntwPFJjk1yEHAusHW4QJI1TYc5wGXAtc3xdUme0mw/DXgxsKOqCvgwcHJzzak8vs9FkjRhvXW2V9XeJJuBm4EDgGuranuSy4HpqtrKICFcmaSATwBvaC5/NnB1czzAVVX1uebc7wPvT/J2YA/wmr7qIEmaXwa/5K9sU1NTNT09vdhhSNKykuSOqpqar5wz2yVJnZhIJEmdmEgkSZ2YSCRJnZhIJEmdmEgkSZ2YSCRJnZhIJEmdrIoJiUn2APcu4JI1rM7l6Vdjva3z6rAa6wzd672+quZdrHBVJJKFSjLdZjbnSrMa622dV4fVWGeYXL19tCVJ6sREIknqxEQysy2LHcAiWY31ts6rw2qsM0yo3vaRSJI6sUUiSepkVSeSJKcl2ZFkZ5JLZzj/5CQfbM5/OsmGyUc5Xi3q/LtJvpDk7iTbkqxfjDjHbb56D5X79SSVZNmP8GlT5yS/2Xzf25P8xaRjHLcWf79/NsktSe5s/o6/bDHiHKck1yb5dpLPz3I+Sd7Z/EzuTjLj68k7qapV+YfBWxu/CvwccBBwF7BxpMzFwJ822+cCH1zsuCdQ51OAn2y2X7/c69y23k25Qxm8qfM2YGqx457Ad308cCfwtGb/pxc77gnUeQvw+mZ7I/D1xY57DPX+l8Dzgc/Pcv5lwN8yeNvsScCnxx3Dam6RnAjsrKp7quoR4HrgzJEyZwLva7b/F3BqkkwwxnGbt85VdUtVPdTs3gasm3CMfWjzXQNcAbwNeHiSwfWkTZ1/G7imqr4HUFXfnnCM49amzgUc1mwfDuyeYHy9qKpPAA/MUeRM4LoauA14apKfGWcMqzmRHA3cN7S/qzk2Y5mq2gs8CBwxkej60abOwy5k8JvMcjdvvZM8Dzimqv5mkoH1qM13/QzgGUk+meS2JKdNLLp+tKnzHwLnJ9kF3AT8u8mEtqgW+v/9gh04zpstMzO1LEaHsLUps5y0rk+S84EpYFOvEU3GnPVO8iTgvwEXTCqgCWjzXR/I4PHWyQxann+f5DlV9f2eY+tLmzqfB7y3qq5O8kLg/U2dH+0/vEXT+79jq7lFsgs4Zmh/HU9s5j5WJsmBDJrCczUhl7o2dSbJvwbeDJxRVT+aUGx9mq/ehwLPAW5N8nUGz5G3LvMO97Z/v/9PVf24qr4G7GCQWJarNnW+ELgBoKo+BRzMYD2qlazV//ddrOZEcjtwfJJjkxzEoDN960iZrcCrm+1fBz5WTe/VMjVvnZtHPH/GIIks92fm+8xZ76p6sKrWVNWGqtrAoG/ojKqaXpxwx6LN3++/ZjC4giRrGDzqumeiUY5Xmzp/AzgVIMmzGSSSPRONcvK2Aq9qRm+dBDxYVd8c5wes2kdbVbU3yWbgZgajPa6tqu1JLgemq2or8B4GTd+dDFoi5y5exN21rPN/BQ4BbmzGFXyjqs5YtKDHoGW9V5SWdb4Z+JUkXwD+EXhTVX138aLupmWdfw/4H0neyODxzgXL/JdDkvwlg8eTa5q+n/8M/ARAVf0pg76glwE7gYeA14w9hmX+M5QkLbLV/GhLkjQGJhJJUicmEklSJyYSSVInJhJJUicmEmkRJDkqyfVJvtqsvntTkmcsdlzS/jCRSBPWLPz5IeDWqvr5qtoI/EfgyMWNTNo/q3ZCorSITgF+3EwWA6CqPruI8Uid2CKRJu85wB2LHYQ0LiYSSVInJhJp8rYDJyx2ENK4mEikyfsY8OQkv73vQJJfSrIS3v2iVchFG6VFkOTpwNsZtEweBr4O/E5VfWUx45L2h4lEktSJj7YkSZ2YSCRJnZhIJEmdmEgkSZ2YSCRJnZhIJEmdmEgkSZ2YSCRJnfx/IpcGNj3v9ccAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimize the C hyperparameter for regularization \n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.scatter(c_values, accuracy, s = 1.2)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('C')\n",
    "best_c = c_values[accuracy.index(max(accuracy))]\n",
    "print('Best C Value:', best_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.089999999999999997, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = LogisticRegression(C = best_c, solver = 'liblinear')\n",
    "final_model.fit(X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('easi', 1.1719874134635073)\n",
      "('awesom', 0.75278095350308971)\n",
      "('smooth', 0.73446891507511525)\n",
      "('tasti', 0.71961684670303983)\n",
      "('rye', 0.6801721932874395)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print (best_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('drain', -1.072984516223815)\n",
      "('drainpour', -0.88525673107611524)\n",
      "('worst', -0.82315189352896811)\n",
      "('aw', -0.80477925089616498)\n",
      "('chemic', -0.78478930639831357)\n"
     ]
    }
   ],
   "source": [
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['avg_sent'] = train['text'].apply(avgSentiment, args = (feature_to_coef,))\n",
    "train['#pos_words'] = train['text'].apply(posWords, args = (feature_to_coef,))\n",
    "train['#neg_words'] = train['text'].apply(negWords, args = (feature_to_coef,))\n",
    "train['#pos/#neg'] = train['#pos_words']/train['#neg_words']\n",
    "# Some values turn to infinite due to 0 divison, its fixed below\n",
    "mask = train['#pos/#neg'] != np.inf\n",
    "# Make values that infinite equal to the # pos words\n",
    "train.loc[~mask, '#pos/#neg' ] = train.loc[~mask, '#pos_words']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:18: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n"
     ]
    }
   ],
   "source": [
    "open_beer = pd.read_csv('open-beer-database.csv', sep = ';').rename(columns = {'Name':'name'})\n",
    "open_beer = open_beer[['name','Country']]\n",
    "open_beer.drop_duplicates(inplace = True)\n",
    "one_hot = pd.get_dummies(open_beer['Country'])\n",
    "open_beer.drop('Country', axis = 1, inplace = True)\n",
    "open_beer = open_beer.join(one_hot)\n",
    "beer_names = list(set(open_beer['name'].values))\n",
    "\n",
    "# Compress one hot encoding to get one beer and all locations into one row\n",
    "beer_locs = []\n",
    "for beer in beer_names:\n",
    "    cur_beer = open_beer[open_beer['name'] == beer]\n",
    "    t = np.zeros(one_hot.shape[1])\n",
    "    for row in cur_beer.iterrows():\n",
    "        index, data = row\n",
    "        t = np.add( t, np.array(data)[1:])\n",
    "    beer_locs.append(t)   \n",
    "final_hot = pd.DataFrame.from_items(zip(one_hot.columns, np.array(beer_locs).T))\n",
    "final_hot['name'] = beer_names\n",
    "\n",
    "merged = pd.merge(train, final_hot, on = 'name', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('train.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
