{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from datetime import datetime\n",
    "\n",
    "def goodRating(row):\n",
    "    return row >= 3\n",
    "\n",
    "def avgSentiment(row, w_dict):\n",
    "    s = 0\n",
    "    tokens = row.split()\n",
    "    for t in tokens:\n",
    "         s += w_dict[t]\n",
    "    return s/len(tokens)\n",
    "\n",
    "def avgSentiment(row, w_dict):\n",
    "    s = 0\n",
    "    count = 0\n",
    "    tokens = row.split()\n",
    "    for t in tokens:\n",
    "        try:\n",
    "            s += w_dict[t]\n",
    "            count += 1\n",
    "        except:\n",
    "            continue\n",
    "    return s/count\n",
    "\n",
    "def posWords(row, w_dict):\n",
    "    numWords = 0\n",
    "    tokens = row.split()\n",
    "    for t in tokens:\n",
    "        try: \n",
    "            if w_dict[t] > 0:\n",
    "                numWords += 1\n",
    "        except:\n",
    "            continue\n",
    "    return numWords\n",
    "\n",
    "def negWords(row, w_dict):\n",
    "    numWords = 0\n",
    "    tokens = row.split()\n",
    "    for t in tokens:\n",
    "        try: \n",
    "            if w_dict[t] < 0:\n",
    "                numWords += 1\n",
    "        except:\n",
    "            continue\n",
    "    return numWords\n",
    "\n",
    "def date_to_nth_day(date, format='%Y-%m-%d'):\n",
    "    date = pd.to_datetime(date, format=format)\n",
    "    new_year_day = pd.Timestamp(year=date.year, month=1, day=1)\n",
    "    return (date - new_year_day).days + 1\n",
    "\n",
    "# Porter stemmer for text stemming\n",
    "porter = PorterStemmer()\n",
    "\n",
    "stop = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \n",
    "        \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \n",
    "        \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \n",
    "        \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \n",
    "        \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \n",
    "        \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \n",
    "        \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \n",
    "        \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \n",
    "        \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \n",
    "        \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \n",
    "        \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \n",
    "        \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \n",
    "        \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "def avg_word(sentence):\n",
    "    words = sentence.split()\n",
    "    return (sum(len(word) for word in words)/len(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABV</th>\n",
       "      <th>name</th>\n",
       "      <th>style</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>overall</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>text</th>\n",
       "      <th>timeStruct</th>\n",
       "      <th>timeUnix</th>\n",
       "      <th>ageInSeconds</th>\n",
       "      <th>birthdayRaw</th>\n",
       "      <th>birthdayUnix</th>\n",
       "      <th>gender</th>\n",
       "      <th>profileName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Chiostro</td>\n",
       "      <td>Herbed / Spiced Beer</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Pours a clouded gold with a thin white head. N...</td>\n",
       "      <td>{'min': 38, 'hour': 3, 'mday': 16, 'sec': 10, ...</td>\n",
       "      <td>1229398690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RblWthACoz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>Bearded Pat's Barleywine</td>\n",
       "      <td>American Barleywine</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>12oz bottle into 8oz snifter.\\t\\tDeep ruby red...</td>\n",
       "      <td>{'min': 38, 'hour': 23, 'mday': 8, 'sec': 58, ...</td>\n",
       "      <td>1218238738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BeerSox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>Naughty Nellie's Ale</td>\n",
       "      <td>American Pale Ale (APA)</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>First enjoyed at the brewpub about 2 years ago...</td>\n",
       "      <td>{'min': 7, 'hour': 18, 'mday': 26, 'sec': 2, '...</td>\n",
       "      <td>1101492422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>mschofield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4</td>\n",
       "      <td>Pilsner Urquell</td>\n",
       "      <td>Czech Pilsener</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>First thing I noticed after pouring from green...</td>\n",
       "      <td>{'min': 7, 'hour': 1, 'mday': 20, 'sec': 5, 'y...</td>\n",
       "      <td>1308532025</td>\n",
       "      <td>1.20983e+09</td>\n",
       "      <td>Aug 10, 1976</td>\n",
       "      <td>2.08508e+08</td>\n",
       "      <td>Male</td>\n",
       "      <td>molegar76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.4</td>\n",
       "      <td>Black Sheep Ale (Special)</td>\n",
       "      <td>English Pale Ale</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>A: pours an amber with a one finger head but o...</td>\n",
       "      <td>{'min': 51, 'hour': 6, 'mday': 12, 'sec': 48, ...</td>\n",
       "      <td>1299912708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brewbro000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ABV                       name                    style appearance aroma  \\\n",
       "0    5                   Chiostro     Herbed / Spiced Beer          4     4   \n",
       "1   11   Bearded Pat's Barleywine      American Barleywine          4   3.5   \n",
       "2  4.7       Naughty Nellie's Ale  American Pale Ale (APA)        3.5     4   \n",
       "3  4.4            Pilsner Urquell           Czech Pilsener          3     3   \n",
       "4  4.4  Black Sheep Ale (Special)         English Pale Ale          4     3   \n",
       "\n",
       "  overall palate taste                                               text  \\\n",
       "0       4      4     4  Pours a clouded gold with a thin white head. N...   \n",
       "1     3.5    3.5     3  12oz bottle into 8oz snifter.\\t\\tDeep ruby red...   \n",
       "2     3.5    3.5   3.5  First enjoyed at the brewpub about 2 years ago...   \n",
       "3     2.5      3     3  First thing I noticed after pouring from green...   \n",
       "4       3    3.5   2.5  A: pours an amber with a one finger head but o...   \n",
       "\n",
       "                                          timeStruct    timeUnix ageInSeconds  \\\n",
       "0  {'min': 38, 'hour': 3, 'mday': 16, 'sec': 10, ...  1229398690          NaN   \n",
       "1  {'min': 38, 'hour': 23, 'mday': 8, 'sec': 58, ...  1218238738          NaN   \n",
       "2  {'min': 7, 'hour': 18, 'mday': 26, 'sec': 2, '...  1101492422          NaN   \n",
       "3  {'min': 7, 'hour': 1, 'mday': 20, 'sec': 5, 'y...  1308532025  1.20983e+09   \n",
       "4  {'min': 51, 'hour': 6, 'mday': 12, 'sec': 48, ...  1299912708          NaN   \n",
       "\n",
       "    birthdayRaw birthdayUnix gender profileName  \n",
       "0           NaN          NaN    NaN  RblWthACoz  \n",
       "1           NaN          NaN    NaN     BeerSox  \n",
       "2           NaN          NaN   Male  mschofield  \n",
       "3  Aug 10, 1976  2.08508e+08   Male   molegar76  \n",
       "4           NaN          NaN    NaN  Brewbro000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data400_share/beer.csv\")\n",
    "data.drop('index',axis =1, inplace = True)\n",
    "newCols = [col.split('/')[1] for col in data.columns]\n",
    "data = pd.DataFrame(data.values, columns = newCols).drop(['beerId','brewerId'], axis = 1)\n",
    "train=data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sumReviews'] = train['appearance'] + train['aroma'] + train['overall'] + train['palate'] + train['taste']\n",
    "sumMean = train['sumReviews'].mean()\n",
    "train['sumReviews'] =  train['sumReviews'].astype(float)\n",
    "userSumMean = train.groupby(['profileName'])['sumReviews'].mean().reset_index()\n",
    "userSumMean['userBias'] = userSumMean['sumReviews'] - sumMean\n",
    "train = train.merge(userSumMean, left_on='profileName', right_on='profileName', how='left')\n",
    "train = train.drop(['sumReviews_y','sumReviews_x'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Additional featureW\n",
    "train['word_count'] = train['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "train['char_count'] = train['text'].str.len() ## this also includes spaces\n",
    "train['avg_word_len'] = train['text'].apply(lambda x: avg_word(str(x)))\n",
    "train['stopwords'] = train['text'].apply(lambda x: len([x for x in str(x).split() if x in stop]))\n",
    "train['questions'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '?' in str(x)]))\n",
    "train['ellipses'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '...' in str(x)]))\n",
    "train['exclamations'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '!' in str(x)]))\n",
    "train['plus'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '+' in str(x)]))\n",
    "train['star'] = train['text'].apply(lambda x: len([x for x in str(x).split() if '*' in str(x)]))\n",
    "train['numerics'] = train['text'].apply(lambda x: len([x for x in str(x).split() if x.isdigit()]))\n",
    "train['upper'] = train['text'].str.findall(r'[A-Z]').str.len()\n",
    "train[\"age_years\"] = (train['ageInSeconds']/31536000.0)#.apply(np.floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"timeStruct\"] = train[\"timeStruct\"].apply(lambda x: dict(eval(x)))\n",
    "beerTimeDic = train[\"timeStruct\"]\n",
    "\n",
    "holidays =[\n",
    "  '2012-01-02',\n",
    "  '2012-01-16',\n",
    "  '2012-02-20',\n",
    "  '2012-05-28',\n",
    "  '2012-07-04',\n",
    "  '2012-09-03',\n",
    "  '2012-10-08',\n",
    "  '2012-11-12',\n",
    "  '2012-11-22',\n",
    "  '2012-12-25']\n",
    "\n",
    "ydayHoliday = []\n",
    "for date in holidays:\n",
    "    ydayHoliday.append(date_to_nth_day(date))\n",
    "    \n",
    "weekHoliday = []\n",
    "for day in ydayHoliday:\n",
    "    temp = list(range(day-3,day+3))\n",
    "    temp = [x for x in temp if(x>0 & x<367)]\n",
    "    for x in temp:\n",
    "        weekHoliday.append(x)\n",
    "        \n",
    "train[\"isHolidayWeek\"] = train[\"timeStruct\"].apply(lambda x: 1 if x['yday'] in weekHoliday else 0)\n",
    "train[\"isWeekend\"] = train[\"timeStruct\"].apply(lambda x: 1 if x['wday'] in [4,5,6] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert reviews to lower case\n",
    "train['text'] = train['text'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "\n",
    "# Remove punctuation characters from  text review\n",
    "train['text'] = train['text'].str.replace('[^\\w\\s]','')\n",
    "# Remove stop words\n",
    "train['text'] = train['text'].apply(lambda x: \" \".join(x for x in str(x).split() if x not in stop))\n",
    "\n",
    "# Stem words\n",
    "train['text'] = train['text'].apply((lambda x: \" \".join(porter.stem(x) for x in str(x).split())))\n",
    "\n",
    "# Remove least frequent words\n",
    "l_freq = pd.Series(' '.join(train['text']).split()).value_counts()[-10:]\n",
    "l_freq = list(l_freq.index)\n",
    "train['text'] = train['text'].apply(lambda x: \" \".join(x for x in str(x).split() if x not in l_freq))\n",
    "\n",
    "# Label beer ratings as positive or negative\n",
    "train['target'] = train['overall'].apply(goodRating)\n",
    "train.sort_values(by = 'overall', ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = train['text'].values\n",
    "target = train['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize words from beer rating text\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(text_train)\n",
    "X = cv.transform(text_train)\n",
    "#X_test = cv.transform(reviews_test_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "c_values = np.linspace(.01,1,100)\n",
    "accuracy = []\n",
    "for c in c_values:\n",
    "    lr = LogisticRegression(C=c, solver='liblinear')\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "          # % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    accuracy.append(accuracy_score(y_val, lr.predict(X_val)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C Value: 0.08\n"
     ]
    }
   ],
   "source": [
    "# Optimize the C hyperparameter for regularization \n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.scatter(c_values, accuracy, s = 1.2)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('C')\n",
    "best_c = c_values[accuracy.index(max(accuracy))]\n",
    "print('Best C Value:', best_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.080000000000000002, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = LogisticRegression(C = best_c, solver = 'liblinear')\n",
    "final_model.fit(X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('easi', 1.1442306590485964)\n",
      "('smooth', 0.73020702865734921)\n",
      "('awesom', 0.71731045205592303)\n",
      "('tasti', 0.70110263546226415)\n",
      "('session', 0.65563099330781738)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print (best_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('drain', -1.0297727499247824)\n",
      "('drainpour', -0.82669611137271504)\n",
      "('worst', -0.79515021215335724)\n",
      "('aw', -0.77418393299343213)\n",
      "('chemic', -0.74254519692457199)\n"
     ]
    }
   ],
   "source": [
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['avg_sent'] = train['text'].apply(avgSentiment, args = (feature_to_coef,))\n",
    "train['#pos_words'] = train['text'].apply(posWords, args = (feature_to_coef,))\n",
    "train['#neg_words'] = train['text'].apply(negWords, args = (feature_to_coef,))\n",
    "train['#pos/#neg'] = train['#pos_words']/train['#neg_words']\n",
    "# Some values turn to infinite due to 0 divison, its fixed below\n",
    "mask = train['#pos/#neg'] != np.inf\n",
    "# Make values that infinite equal to the # pos words\n",
    "train.loc[~mask, '#pos/#neg' ] = train.loc[~mask, '#pos_words']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:18: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n"
     ]
    }
   ],
   "source": [
    "open_beer = pd.read_csv('open-beer-database.csv', sep = ';').rename(columns = {'Name':'name'})\n",
    "open_beer = open_beer[['name','Country']]\n",
    "open_beer.drop_duplicates(inplace = True)\n",
    "one_hot = pd.get_dummies(open_beer['Country'])\n",
    "open_beer.drop('Country', axis = 1, inplace = True)\n",
    "open_beer = open_beer.join(one_hot)\n",
    "beer_names = list(set(open_beer['name'].values))\n",
    "\n",
    "# Compress one hot encoding to get one beer and all locations into one row\n",
    "beer_locs = []\n",
    "for beer in beer_names:\n",
    "    cur_beer = open_beer[open_beer['name'] == beer]\n",
    "    t = np.zeros(one_hot.shape[1])\n",
    "    for row in cur_beer.iterrows():\n",
    "        index, data = row\n",
    "        t = np.add( t, np.array(data)[1:])\n",
    "    beer_locs.append(t)   \n",
    "final_hot = pd.DataFrame.from_items(zip(one_hot.columns, np.array(beer_locs).T))\n",
    "final_hot['name'] = beer_names\n",
    "\n",
    "merged = pd.merge(train, final_hot, on = 'name', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['ABV',\n",
    " 'appearance',\n",
    " 'aroma',\n",
    " 'overall',\n",
    " 'palate',\n",
    " 'taste',\n",
    " 'ageInSeconds',\n",
    " 'userBias',\n",
    " 'word_count',\n",
    " 'char_count',\n",
    " 'avg_word_len',\n",
    " 'stopwords',\n",
    " 'questions',\n",
    " 'ellipses',\n",
    " 'exclamations',\n",
    " 'plus',\n",
    " 'star',\n",
    " 'numerics',\n",
    " 'upper',\n",
    " 'age_years',\n",
    " 'avg_sent',\n",
    " '#pos_words',\n",
    " '#neg_words',\n",
    " '#pos/#neg']\n",
    "\n",
    "for col in num_cols:    \n",
    "    minimum = train[col].min()\n",
    "    maximum = train[col].max()\n",
    "    train[col] = (train[col]-(minimum-.00000001)) / (maximum-minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('train.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
