{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(object):\n",
    "    \n",
    "    def __call__(self, predicted, actual):\n",
    "        \"\"\"Calculates the loss as a function of the prediction and the actual.\n",
    "        \n",
    "        Args:\n",
    "          predicted (np.ndarray, float): the predicted output labels\n",
    "          actual (np.ndarray, float): the actual output labels\n",
    "          \n",
    "        Returns: (float) \n",
    "          The value of the loss for this batch of observations.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def derivative(self, predicted, actual):\n",
    "        \"\"\"The derivative of the loss with respect to the prediction.\n",
    "        \n",
    "        Args:\n",
    "          predicted (np.ndarray, float): the predicted output labels\n",
    "          actual (np.ndarray, float): the actual output labels\n",
    "          \n",
    "        Returns: (np.ndarray, float) \n",
    "          The derivatives of the loss.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        \n",
    "class SquaredErrorLoss(Loss):\n",
    "    \n",
    "    def __call__(self, predicted, actual):\n",
    "        return 0.5*np.sum(\n",
    "            np.multiply((predicted - actual), (predicted - actual))\n",
    "        )\n",
    "    \n",
    "    def delta(self, z_prime, predicted, actual):\n",
    "        return (\n",
    "            np.multiply((predicted - actual), z_prime.T)\n",
    "        )\n",
    "\n",
    "class crossEntropy(Loss):\n",
    "    \n",
    "    def __call__(self, predicted, actual):\n",
    "        return np.sum(\n",
    "            np.nan_to_num(np.multiply(-actual,np.log(predicted))-np.multiply((1-actual),np.log(1-predicted)))\n",
    "        )\n",
    "    \n",
    "    def delta(self, z_prime, predicted, actual):\n",
    "        return (\n",
    "            (predicted-actual)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationFunction(object):\n",
    "        \n",
    "    def __call__(self, a):\n",
    "        \"\"\"Applies activation function to the values in a layer.\n",
    "        \n",
    "        Args:\n",
    "          a (np.ndarray, float): the values from the previous layer (after \n",
    "            multiplying by the weights.\n",
    "          \n",
    "        Returns: (np.ndarray, float) \n",
    "          The values h = g(a).\n",
    "        \"\"\"\n",
    "        return a\n",
    "    \n",
    "    def derivative(self, h):\n",
    "        \"\"\"The derivatives as a function of the outputs at the nodes.\n",
    "        \n",
    "        Args:\n",
    "          h (np.ndarray, float): the outputs h = g(a) at the nodes.\n",
    "          \n",
    "        Returns: (np.ndarray, float) \n",
    "          The derivatives dh/da.\n",
    "        \"\"\"\n",
    "        return np.ones(h.shape)\n",
    "    \n",
    "class ReLU(ActivationFunction):\n",
    "    \n",
    "    def __call__(self, a):\n",
    "        return np.where(a > 0, a, 0)\n",
    "    \n",
    "    def derivative(self, a):\n",
    "        return np.where(a > 0, 1, 0)\n",
    "\n",
    "class Sigmoid(ActivationFunction):\n",
    "    \n",
    "    def __call__(self, a):\n",
    "        return 1/(1 + np.exp(-a))\n",
    "    \n",
    "    def derivative(self, a):\n",
    "        e = self.__call__(a)\n",
    "        return  np.multiply(e, (1 - e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    \"\"\"A data structure for a layer in a neural network.\n",
    "    \n",
    "    Attributes:\n",
    "      num_nodes (int): number of nodes in the layer\n",
    "      activation_function (ActivationFunction)\n",
    "      values_pre_activation (np.ndarray, float): most recent values\n",
    "        in layer, before applying activation function\n",
    "      values_post_activation (np.ndarray, float): most recent values\n",
    "        in layer, after applying activation function\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_nodes, activation_function=ActivationFunction()):\n",
    "        self.num_nodes = num_nodes\n",
    "        self.activation_function = activation_function\n",
    "        \n",
    "    def get_layer_values(self, values_pre_activation):\n",
    "        \"\"\"Applies activation function to values from previous layer.\n",
    "        \n",
    "        Stores the values (both before and after applying activation \n",
    "        function)\n",
    "        \n",
    "        Args:\n",
    "          values_pre_activation (np.ndarray, float): \n",
    "            A (batch size) x self.num_nodes array of the values\n",
    "            in layer before applying the activation function\n",
    "        \n",
    "        Returns: (np.ndarray, float)\n",
    "            A (batch size) x self.num_nodes array of the values\n",
    "            in layer after applying the activation function\n",
    "        \"\"\"\n",
    "        self.values_pre_activation = values_pre_activation\n",
    "        self.values_post_activation = self.activation_function(\n",
    "            values_pre_activation\n",
    "        )\n",
    "        return self.values_post_activation\n",
    "    \n",
    "    def get_layer_derivatives(self, values_pre_activation):\n",
    "        return self.activation_function.derivative(\n",
    "            values_pre_activation\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedNeuralNetwork(object):\n",
    "    \"\"\"A data structure for a fully-connected neural network.\n",
    "    \n",
    "    Attributes:\n",
    "      layers (Layer): A list of Layer objects.\n",
    "      loss (Loss): The loss function to use in training.\n",
    "      learning_rate (float): The learning rate to use in backpropagation.\n",
    "      weights (list, np.ndarray): A list of weight matrices,\n",
    "        length should be len(self.layers) - 1\n",
    "      biases (list, float): A list of bias terms,\n",
    "        length should be equal to len(self.layers)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layers, loss, learning_rate):\n",
    "        self.layers = layers\n",
    "        self.loss = loss\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # initialize weight matrices and biases to zeros\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        mu, sigma = 0, 1\n",
    "        for i in range(1, len(self.layers)):\n",
    "            w = np.matrix(np.random.normal(mu, sigma, (self.layers[i - 1].num_nodes, self.layers[i].num_nodes))/np.sqrt(self.layers[i - 1].num_nodes))\n",
    "            self.weights.append(w)\n",
    "            self.biases.append(np.zeros(self.layers[i].num_nodes))\n",
    "        \n",
    "    def feedforward(self, inputs):\n",
    "        \"\"\"Predicts the output(s) for a given set of input(s).\n",
    "        \n",
    "        Args:\n",
    "          inputs (np.ndarray, float): A (batch size) x self.layers[0].num_nodes array\n",
    "          \n",
    "        Returns: (np.ndarray, float) \n",
    "          An array of the predicted output labels, length is the batch size\n",
    "        \"\"\"\n",
    "        self.storedValuesZ = [inputs]\n",
    "        self.storedValuesA = [inputs]\n",
    "        a = inputs\n",
    "        \n",
    "        ## Iterate layers\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            ## g(hw + b),  h = previous layer values\n",
    "            if i != len(self.layers) - 1:\n",
    "                z = np.matrix(np.add(a * self.weights[i], np.matrix(self.biases[i])))\n",
    "                self.storedValuesZ.append(z)\n",
    "                a = np.matrix(self.layers[i + 1].get_layer_values(z))\n",
    "                self.storedValuesA.append(a)\n",
    "        return a\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        a = inputs\n",
    "        ## Iterate layers\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            ## g(hw + b),  h = previous layer values\n",
    "            if i != len(self.layers) - 1:\n",
    "                z = np.matrix(np.add(a * self.weights[i], np.matrix(self.biases[i])))\n",
    "                a = self.layers[i+1].get_layer_values(z)\n",
    "        return a\n",
    "    \n",
    "    def backProp(self, predicted, actual):\n",
    "        gradient_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        gradient_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        # Update First weights\n",
    "        z_prime = 0\n",
    "        if (type(self.loss) == type(SquaredErrorLoss())):\n",
    "            z_prime = self.layers[-1].get_layer_derivatives(self.storedValuesZ[-1]).T\n",
    "        delta = self.loss.delta(z_prime, predicted, actual).T\n",
    "        dLdw = np.multiply(delta,self.storedValuesA[-2]).T\n",
    "        \n",
    "        gradient_b[-1] = delta.T\n",
    "        gradient_w[-1] = dLdw\n",
    "        #self.updatedWeights[-1]= self.weights[-1] - self.learning_rate * dLdw\n",
    "        #self.updatedBiases[-1] = self.biases[-1] - np.multiply(self.learning_rate, delta).T\n",
    "        \n",
    "        # Update rest of the weights\n",
    "        for l in range(2, len(self.layers)):\n",
    "            z = self.storedValuesZ[-l]\n",
    "            dadz = self.layers[-l].get_layer_derivatives(z)\n",
    "            delta = np.multiply(self.weights[-l + 1] * delta, dadz.T)\n",
    "            dLdw = np.multiply(delta, self.storedValuesA[-l - 1]).T\n",
    "            gradient_b[-l] = delta.T\n",
    "            gradient_w[-l] = dLdw\n",
    "            #self.updatedBiases[-l] = self.biases[-l] - np.multiply(self.learning_rate, delta).T\n",
    "            #self.updatedWeights[-l] = self.weights[-l] - np.multiply(self.learning_rate, np.dot(delta, self.storedValuesA[-l - 1])).T\n",
    "        return (gradient_b, gradient_w)\n",
    "        \n",
    "    def train(self, inputs, labels):\n",
    "        \"\"\"Trains neural network based on a batch of training data.\n",
    "        \n",
    "        Args:\n",
    "          inputs (np.ndarray): A (batch size) x self.layers[0].num_nodes array\n",
    "          labels (np.ndarray): An array of ground-truth output labels, \n",
    "            length is the batch size.\n",
    "        \"\"\"\n",
    "        predicted = self.feedforward(inputs)\n",
    "        gradient_b, gradient_w = self.backProp(predicted, labels)\n",
    "        return (gradient_b, gradient_w, self.loss(predicted,labels))\n",
    "    \n",
    "    def getWeights(self):\n",
    "        return(self.weights)\n",
    "    \n",
    "    def train_epochs_minibatch(self, inputs, labels, epochs = 10, mini_batch=1):\n",
    "        '''\n",
    "        Args:\n",
    "          inputs (np.ndarray): A x self.layers[0].num_nodes array\n",
    "          labels (np.ndarray): An array of ground-truth output labels, \n",
    "            length is the inputs size.\n",
    "          epochs (int): Number of times the data is iterated through\n",
    "          mini_batch (int): Number of observations to train at a time\n",
    "        '''\n",
    "        if (inputs.shape[0] < mini_batch):\n",
    "            mini_batch = inputs.shape[0]\n",
    "        meanLossEpochs = []\n",
    "        for i in range(epochs):\n",
    "            print('Epoch#:',i)\n",
    "            sum_gradient_b = [np.zeros(b.shape) for b in self.biases]\n",
    "            sum_gradient_w = [np.zeros(w.shape) for w in self.weights]\n",
    "            sumLoss = 0\n",
    "            randomIndices = np.random.choice([i for i in range(len(inputs))], size=inputs.shape[0], replace=False)\n",
    "            for index, row in enumerate(randomIndices):\n",
    "                gradient_b, gradient_w, loss = self.train(np.matrix([inputs[row]]),np.matrix([labels[row]]))\n",
    "                sumLoss += loss\n",
    "                sum_gradient_b = [sb+gb for sb, gb in zip(sum_gradient_b,gradient_b)]\n",
    "                sum_gradient_w = [sw+gw for sw, gw in zip(sum_gradient_w, gradient_w)]\n",
    "                if ((index+1)%mini_batch == 0 or (index+1) == inputs.shape[0]):\n",
    "                    self.biases = [b-(self.learning_rate/mini_batch)*sb\n",
    "                                      for b, sb in zip(self.biases, sum_gradient_b)]\n",
    "                    self.weights = [w-(self.learning_rate/mini_batch)*sw\n",
    "                                     for w, sw in zip(self.weights, sum_gradient_w)]\n",
    "                    sum_gradient_b = [np.zeros(b.shape) for b in self.biases]\n",
    "                    sum_gradient_w = [np.zeros(w.shape) for w in self.weights]\n",
    "            avg_loss = sumLoss/inputs.shape[0]\n",
    "            meanLossEpochs.append(avg_loss)\n",
    "        return (meanLossEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid must be applied to the last layer inorder for it to work\n",
    "network = FullyConnectedNeuralNetwork(\n",
    "    layers=[Layer(179), Layer(50, ReLU()), Layer(20), Layer(1, Sigmoid())],\n",
    "    loss = crossEntropy(),\n",
    "    learning_rate=0.005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABV</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>overall</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>userBias</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>...</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Sri Lanka</th>\n",
       "      <th>Sweden</th>\n",
       "      <th>Switzerland</th>\n",
       "      <th>Taiwan, Province of China</th>\n",
       "      <th>Thailand</th>\n",
       "      <th>Togo</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <th>United States</th>\n",
       "      <th>Location Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.092014</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.135916</td>\n",
       "      <td>0.312620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.192708</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.766250</td>\n",
       "      <td>0.238418</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.270866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.114124</td>\n",
       "      <td>0.119221</td>\n",
       "      <td>0.425918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.123264</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.711000</td>\n",
       "      <td>0.213559</td>\n",
       "      <td>0.221747</td>\n",
       "      <td>0.344344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.175347</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.211299</td>\n",
       "      <td>0.209332</td>\n",
       "      <td>0.288806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ABV  appearance  aroma  overall  palate  taste  userBias  word_count  \\\n",
       "0  0.092014         0.7  0.750      1.0   0.750  0.875  0.745000    0.135593   \n",
       "1  0.192708         0.8  1.000      1.0   1.000  1.000  0.766250    0.238418   \n",
       "2  0.111111         0.8  0.875      1.0   0.875  0.875  0.775000    0.114124   \n",
       "3  0.123264         0.8  0.875      1.0   0.750  0.875  0.711000    0.213559   \n",
       "4  0.175347         0.8  0.875      1.0   0.875  0.875  0.755556    0.211299   \n",
       "\n",
       "   char_count  avg_word_len        ...         Spain  Sri Lanka  Sweden  \\\n",
       "0    0.135916      0.312620        ...           0.0        0.0     0.0   \n",
       "1    0.232877      0.270866        ...           0.0        0.0     0.0   \n",
       "2    0.119221      0.425918        ...           0.0        0.0     0.0   \n",
       "3    0.221747      0.344344        ...           0.0        0.0     0.0   \n",
       "4    0.209332      0.288806        ...           0.0        0.0     0.0   \n",
       "\n",
       "   Switzerland  Taiwan, Province of China  Thailand  Togo  United Kingdom  \\\n",
       "0          0.0                        0.0       0.0   0.0             0.0   \n",
       "1          0.0                        0.0       0.0   0.0             0.0   \n",
       "2          0.0                        0.0       0.0   0.0             0.0   \n",
       "3          0.0                        0.0       0.0   0.0             0.0   \n",
       "4          0.0                        0.0       0.0   0.0             0.0   \n",
       "\n",
       "   United States  Location Unknown  \n",
       "0            0.0               0.0  \n",
       "1            0.0               1.0  \n",
       "2            0.0               1.0  \n",
       "3            0.0               1.0  \n",
       "4            0.0               1.0  \n",
       "\n",
       "[5 rows x 184 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependents = ['overall']#['taste','appearance','aroma','palate','overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "independents = []\n",
    "for x in list(test.columns):\n",
    "    if (x not in dependents):\n",
    "        independents.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(independents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeXandY(data, dependentNames, independentName, intercept):\n",
    "    X = np.array(data[dependentNames])\n",
    "    if (intercept):\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "    y = np.array(data[independentName])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = makeXandY(test, independents, dependents, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37500, 179)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37500, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomize = np.random.choice([i for i in range(x.shape[0])], size=x.shape[0], replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = x[randomize[:3750]]\n",
    "testY = y[randomize[:3750]]\n",
    "trainX = x[randomize[3750:]]\n",
    "trainY = y[randomize[3750:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch#: 0\n",
      "Epoch#: 1\n",
      "Epoch#: 2\n",
      "Epoch#: 3\n",
      "Epoch#: 4\n",
      "Epoch#: 5\n",
      "Epoch#: 6\n",
      "Epoch#: 7\n",
      "Epoch#: 8\n",
      "Epoch#: 9\n",
      "Epoch#: 10\n",
      "Epoch#: 11\n",
      "Epoch#: 12\n",
      "Epoch#: 13\n",
      "Epoch#: 14\n",
      "Epoch#: 15\n",
      "Epoch#: 16\n",
      "Epoch#: 17\n",
      "Epoch#: 18\n",
      "Epoch#: 19\n"
     ]
    }
   ],
   "source": [
    "epochsMeanError = network.train_epochs_minibatch(trainX, trainY, epochs=20, mini_batch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict to find error\n",
    "predict = network.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = predict - testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "squardDiff = np.multiply(diff,diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.sum(squardDiff, axis = 0)/testY.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.02006457,  0.00940888,  0.01782851,  0.01783685,  0.0133131 ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse # Great but not standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unstandardized predicted for each dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstandPredict = copy.deepcopy(predict)\n",
    "unstandPredict[:,0] = predict[:,0]*5+(-1e-08)\n",
    "unstandTestY = copy.deepcopy(testY)\n",
    "unstandTestY[:,0] = testY[:,0]*5+(-1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.34713103]]\n"
     ]
    }
   ],
   "source": [
    "diff = unstandPredict - unstandTestY\n",
    "squardDiff = np.multiply(diff,diff)\n",
    "mse = np.sum(squardDiff, axis = 0)/unstandTestY.shape[0]\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.06381652]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(unstandPredict, axis= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unstandardized predicted for all dependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonRegData = pd.read_csv('train_not_reg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABV</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>overall</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>userBias</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>...</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Sri Lanka</th>\n",
       "      <th>Sweden</th>\n",
       "      <th>Switzerland</th>\n",
       "      <th>Taiwan, Province of China</th>\n",
       "      <th>Thailand</th>\n",
       "      <th>Togo</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <th>United States</th>\n",
       "      <th>Location Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.459960</td>\n",
       "      <td>121</td>\n",
       "      <td>684.0</td>\n",
       "      <td>4.432000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.884960</td>\n",
       "      <td>212</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>4.240741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.059960</td>\n",
       "      <td>102</td>\n",
       "      <td>606.0</td>\n",
       "      <td>4.950980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-0.220040</td>\n",
       "      <td>190</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>4.577320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.671071</td>\n",
       "      <td>188</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>4.322917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ABV  appearance  aroma  overall  palate  taste  userBias  word_count  \\\n",
       "0   5.4         3.5    4.0      5.0     4.0    4.5  0.459960         121   \n",
       "1  11.2         4.0    5.0      5.0     5.0    5.0  0.884960         212   \n",
       "2   6.5         4.0    4.5      5.0     4.5    4.5  1.059960         102   \n",
       "3   7.2         4.0    4.5      5.0     4.0    4.5 -0.220040         190   \n",
       "4  10.2         4.0    4.5      5.0     4.5    4.5  0.671071         188   \n",
       "\n",
       "   char_count  avg_word_len        ...         Spain  Sri Lanka  Sweden  \\\n",
       "0       684.0      4.432000        ...           0.0        0.0     0.0   \n",
       "1      1137.0      4.240741        ...           0.0        0.0     0.0   \n",
       "2       606.0      4.950980        ...           0.0        0.0     0.0   \n",
       "3      1085.0      4.577320        ...           0.0        0.0     0.0   \n",
       "4      1027.0      4.322917        ...           0.0        0.0     0.0   \n",
       "\n",
       "   Switzerland  Taiwan, Province of China  Thailand  Togo  United Kingdom  \\\n",
       "0          0.0                        0.0       0.0   0.0             0.0   \n",
       "1          0.0                        0.0       0.0   0.0             0.0   \n",
       "2          0.0                        0.0       0.0   0.0             0.0   \n",
       "3          0.0                        0.0       0.0   0.0             0.0   \n",
       "4          0.0                        0.0       0.0   0.0             0.0   \n",
       "\n",
       "   United States  Location Unknown  \n",
       "0            0.0               0.0  \n",
       "1            0.0               1.0  \n",
       "2            0.0               1.0  \n",
       "3            0.0               1.0  \n",
       "4            0.0               1.0  \n",
       "\n",
       "[5 rows x 184 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonRegData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taste\n",
      "multiply 4.0\n",
      "add 0.99999999\n",
      "appearance\n",
      "multiply 5.0\n",
      "add -1e-08\n",
      "aroma\n",
      "multiply 4.0\n",
      "add 0.99999999\n",
      "palate\n",
      "multiply 4.0\n",
      "add 0.99999999\n",
      "overall\n",
      "multiply 5.0\n",
      "add -1e-08\n"
     ]
    }
   ],
   "source": [
    "# Formula used to standardize\n",
    "# minimum = train[col].min()\n",
    "# maximum = train[col].max()\n",
    "# train[col] = (train[col]-(minimum-.00000001)) / (maximum-minimum)\n",
    "# dependents = ['taste','appearance','aroma','palate','overall']\n",
    "for dep in dependents:\n",
    "    print(dep)\n",
    "    minDep = nonRegData[dep].min()\n",
    "    maxDep = nonRegData[dep].max()\n",
    "    print('multiply',(maxDep-minDep))\n",
    "    print('add', minDep-.00000001)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.75892335,  0.79785564,  0.75117496,  0.74622054,  0.79041425],\n",
       "        [ 0.82727774,  0.84774871,  0.81565502,  0.80789164,  0.860271  ],\n",
       "        [ 0.70340177,  0.7539783 ,  0.68781594,  0.69721566,  0.74261862],\n",
       "        ..., \n",
       "        [ 0.87886278,  0.8743032 ,  0.86785127,  0.8516397 ,  0.88950593],\n",
       "        [ 0.7931613 ,  0.80482041,  0.77662379,  0.77152569,  0.82538341],\n",
       "        [ 0.70215509,  0.77150605,  0.69863589,  0.68523435,  0.7721432 ]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network with all dependents results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstandPredict = copy.deepcopy(predict)\n",
    "unstandPredict[:,0] = predict[:,0]*4+0.99999999\n",
    "unstandPredict[:,1] = predict[:,1]*5+(-1e-08)\n",
    "unstandPredict[:,2] = predict[:,2]*4+0.99999999\n",
    "unstandPredict[:,3] = predict[:,3]*4+0.99999999\n",
    "unstandPredict[:,4] = predict[:,4]*5+-1e-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.09117546,  0.06986612,  0.10521375,  0.09441194,  0.09628214]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(unstandPredict, axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstandTestY = copy.deepcopy(testY)\n",
    "unstandTestY[:,0] = testY[:,0]*4+0.99999999\n",
    "unstandTestY[:,1] = testY[:,1]*5+(-1e-08)\n",
    "unstandTestY[:,2] = testY[:,2]*4+0.99999999\n",
    "unstandTestY[:,3] = testY[:,3]*4+0.99999999\n",
    "unstandTestY[:,4] = testY[:,4]*5+-1e-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32103305  0.23522205  0.28525619  0.28538954  0.33282746]]\n"
     ]
    }
   ],
   "source": [
    "diff = unstandPredict - unstandTestY\n",
    "squardDiff = np.multiply(diff,diff)\n",
    "mse = np.sum(squardDiff, axis = 0)/unstandTestY.shape[0]\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.arange(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'NN One Dependent: taste')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xs,epochsMeanError)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Error')\n",
    "plt.title(\"NN One Dependent: taste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Squared Error Loss Function')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xs,epochsMeanError)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Error')\n",
    "plt.title(\"Squared Error Loss Function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumMSE = 0.015206818375849451 + 0.018871498462694727 + 0.037666860687320523 + 0.022874488092096194 + 0.015563367413306953"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02203660660625357"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumMSE / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
